{
    "title": "Give agents access to MCP Servers",
    "description": "Learn how to add plugins from a MCP Server to your agents in Semantic Kernel.",
    "author": "eavanvalkenburg",
    "content": "# Add plugins from a MCP Server\n\nMCP is the Model Context Protocol, it is an open protocol that is designed to allow additional capabilities to be added to AI applications with ease, see [the documentation](https://modelcontextprotocol.io/introduction) for more info.\nSemantic Kernel allows you to add plugins from a MCP Server to your agents. This is useful when you want to use plugins that are made available as a MCP Server.\n\nSemantic Kernel supports both local MCP Servers, through Stdio, or servers that connect through SSE over HTTPS.\n\n## Add plugins from a local MCP Server\n\nTo add a locally running MCP server, you can use the familiar MCP commands, like `npx`, `docker` or `uvx`, so if you want to run one of those, make sure those are installed.\n\nFor instance when you look into your claude desktop config, or the vscode settings.json, you would see something like this:\n\n```json\n{\n    \"mcpServers\": {\n        \"github\": {\n           \"command\": \"docker\",\n           \"args\": [\n                 \"run\",\n                 \"-i\",\n                 \"--rm\",\n                 \"-e\",\n                 \"GITHUB_PERSONAL_ACCESS_TOKEN\",\n                 \"ghcr.io/github/github-mcp-server\"\n           ],\n           \"env\": {\n                 \"GITHUB_PERSONAL_ACCESS_TOKEN\": \"...\"\n           }\n        }\n    }\n}\n```\n\nIn order to make the same plugin available to your kernel or agent, you would do this:\n\n::: zone pivot=\"programming-language-python\"\n\n```python\nimport os\nfrom semantic_kernel import Kernel\nfrom semantic_kernel.connectors.mcp import MCPStdioPlugin\n\nasync def main():\n    async with MCPStdioPlugin(\n        name=\"Github\",\n        description=\"Github Plugin\",\n        command=\"docker\",\n        args=[\"run\", \"-i\", \"--rm\", \"-e\", \"GITHUB_PERSONAL_ACCESS_TOKEN\", \"ghcr.io/github/github-mcp-server\"],\n        env={\"GITHUB_PERSONAL_ACCESS_TOKEN\": os.getenv(\"GITHUB_PERSONAL_ACCESS_TOKEN\")},\n    ) as github_plugin:\n        kernel = Kernel()\n        kernel.add_plugin(github_plugin)\n        # Do something with the kernel\n```\n\nAn SSE-based MCP server is even simpler as it just needs the URL:\n\n```python\nimport os\nfrom semantic_kernel import Kernel\nfrom semantic_kernel.connectors.mcp import MCPSsePlugin\n\nasync def main():\n    async with MCPSsePlugin(\n        name=\"Github\",\n        description=\"Github Plugin\",\n        url=\"http://localhost:8080\",\n    ) as github_plugin:\n        kernel = Kernel()\n        kernel.add_plugin(github_plugin)\n        # Do something with the kernel\n```\n\nIn both case the async context manager is used to setup the connection and close it, you can also do this manually:\n\n```python\nimport os\nfrom semantic_kernel import Kernel\nfrom semantic_kernel.connectors.mcp import MCPSsePlugin\n\nasync def main():\n    plugin = MCPSsePlugin(\n        name=\"Github\",\n        description=\"Github Plugin\",\n        url=\"http://localhost:8080\",\n    )\n    await plugin.connect()   \n    kernel = Kernel()\n    kernel.add_plugin(github_plugin)\n    # Do something with the kernel\n    await plugin.close()\n```\n\n::: zone-end",
    "filename": "C:\\Work\\sk\\chainlit-demo\\data\\markdowns\\adding-mcp-plugins.md",
    "embedding": "Give agents access to MCP Servers - Learn how to add plugins from a MCP Server to your agents in Semantic Kernel. - # Add plugins from a MCP Server\n\nMCP is the Model Context Protocol, it is an open protocol that is designed to allow additional capabilities to be added to AI applications with ease, see [the documentation](https://modelcontextprotocol.io/introduction) for more info.\nSemantic Kernel allows you to add plugins from a MCP Server to your agents. This is useful when you want to use plugins that are made available as a MCP Server.\n\nSemantic Kernel supports both local MCP Servers, through Stdio, or servers that connect through SSE over HTTPS.\n\n## Add plugins from a local MCP Server\n\nTo add a locally running MCP server, you can use the familiar MCP commands, like `npx`, `docker` or `uvx`, so if you want to run one of those, make sure those are installed.\n\nFor instance when you look into your claude desktop config, or the vscode settings.json, you would see something like this:\n\n```json\n{\n    \"mcpServers\": {\n        \"github\": {\n           \"command\": \"docker\",\n           \"args\": [\n                 \"run\",\n                 \"-i\",\n                 \"--rm\",\n                 \"-e\",\n                 \"GITHUB_PERSONAL_ACCESS_TOKEN\",\n                 \"ghcr.io/github/github-mcp-server\"\n           ],\n           \"env\": {\n                 \"GITHUB_PERSONAL_ACCESS_TOKEN\": \"...\"\n           }\n        }\n    }\n}\n```\n\nIn order to make the same plugin available to your kernel or agent, you would do this:\n\n::: zone pivot=\"programming-language-python\"\n\n```python\nimport os\nfrom semantic_kernel import Kernel\nfrom semantic_kernel.connectors.mcp import MCPStdioPlugin\n\nasync def main():\n    async with MCPStdioPlugin(\n        name=\"Github\",\n        description=\"Github Plugin\",\n        command=\"docker\",\n        args=[\"run\", \"-i\", \"--rm\", \"-e\", \"GITHUB_PERSONAL_ACCESS_TOKEN\", \"ghcr.io/github/github-mcp-server\"],\n        env={\"GITHUB_PERSONAL_ACCESS_TOKEN\": os.getenv(\"GITHUB_PERSONAL_ACCESS_TOKEN\")},\n    ) as github_plugin:\n        kernel = Kernel()\n        kernel.add_plugin(github_plugin)\n        # Do something with the kernel\n```\n\nAn SSE-based MCP server is even simpler as it just needs the URL:\n\n```python\nimport os\nfrom semantic_kernel import Kernel\nfrom semantic_kernel.connectors.mcp import MCPSsePlugin\n\nasync def main():\n    async with MCPSsePlugin(\n        name=\"Github\",\n        description=\"Github Plugin\",\n        url=\"http://localhost:8080\",\n    ) as github_plugin:\n        kernel = Kernel()\n        kernel.add_plugin(github_plugin)\n        # Do something with the kernel\n```\n\nIn both case the async context manager is used to setup the connection and close it, you can also do this manually:\n\n```python\nimport os\nfrom semantic_kernel import Kernel\nfrom semantic_kernel.connectors.mcp import MCPSsePlugin\n\nasync def main():\n    plugin = MCPSsePlugin(\n        name=\"Github\",\n        description=\"Github Plugin\",\n        url=\"http://localhost:8080\",\n    )\n    await plugin.connect()   \n    kernel = Kernel()\n    kernel.add_plugin(github_plugin)\n    # Do something with the kernel\n    await plugin.close()\n```\n\n::: zone-end"
}
{
    "title": "Exploring the Semantic Kernel Azure AI Agent Agent",
    "description": "An exploration of the definition, behaviors, and usage patterns for an Azure AI Agent",
    "author": "moonbox3",
    "content": "# Exploring the Semantic Kernel `AzureAIAgent`\n\n> [!IMPORTANT]\n> This feature is in the experimental stage. Features at this stage are under development and subject to change before advancing to the preview or release candidate stage.\n\nDetailed API documentation related to this discussion is available at:\n\n\n\n::: zone pivot=\"programming-language-python\"\n\n- [`AzureAIAgent`](/python/api/semantic-kernel/semantic_kernel.agents.azure_ai.azure_ai_agent.azureaiagent)\n\n::: zone-end\n\n\n\n## What is an `AzureAIAgent`?\n\nAn `AzureAIAgent` is a specialized agent within the Semantic Kernel framework, designed to provide advanced conversational capabilities with seamless tool integration. It automates tool calling, eliminating the need for manual parsing and invocation. The agent also securely manages conversation history using threads, reducing the overhead of maintaining state. Additionally, the `AzureAIAgent` supports a variety of built-in tools, including file retrieval, code execution, and data interaction via Bing, Azure AI Search, Azure Functions, and OpenAPI.\n\nTo use an `AzureAIAgent`, an Azure AI Foundry Project must be utilized.  The following articles provide an overview of the Azure AI Foundry, how to create and configure a project, and the agent service:\n\n- [What is Azure AI Foundry?](/azure/ai-foundry/what-is-ai-foundry)\n- [The Azure AI Foundry SDK](/azure/ai-foundry/how-to/develop/sdk-overview)\n- [What is Azure AI Agent Service](/azure/ai-services/agents/overview)\n- [Quickstart: Create a new agent](/azure/ai-services/agents/quickstart)\n\n\n## Preparing Your Development Environment\n\nTo proceed with developing an `AzureAIAgent`, configure your development environment with the appropriate packages.\n\n\n\n::: zone pivot=\"programming-language-python\"\n\nInstall the `semantic-kernel` package with the optional Azure dependencies:\n\n```bash\npip install semantic-kernel[azure]\n```\n::: zone-end\n\n\n\n\n## Configuring the AI Project Client\n\nAccessing an `AzureAIAgent` first requires the creation of a project client that is configured for a specific Foundry Project, most commonly by providing a connection string ([The Azure AI Foundry SDK: Getting Started with Projects](/azure/ai-foundry/how-to/develop/sdk-overview#get-started-with-projects)).\n\n\n\n::: zone pivot=\"programming-language-python\"\n\nModify your the `.env` file in the root directory to include:\n\n```bash\nAZURE_AI_AGENT_PROJECT_CONNECTION_STRING = \"<example-connection-string>\"\nAZURE_AI_AGENT_MODEL_DEPLOYMENT_NAME = \"<example-model-deployment-name>\"\n```\n\nor\n\n```bash\nAZURE_AI_AGENT_ENDPOINT = \"<example-endpoint>\"\nAZURE_AI_AGENT_SUBSCRIPTION_ID = \"<example-subscription-id>\"\nAZURE_AI_AGENT_RESOURCE_GROUP_NAME = \"<example-resource-group-name>\"\nAZURE_AI_AGENT_PROJECT_NAME = \"<example-project-name>\"\nAZURE_AI_AGENT_MODEL_DEPLOYMENT_NAME = \"<example-model-deployment-name>\"\n```\n\nOnce the configuration is defined, the client may be created:\n\n```python\nfrom semantic_kernel.agents import AzureAIAgent\n\nasync with (\n    DefaultAzureCredential() as creds,\n    AzureAIAgent.create_client(credential=creds) as client,\n):\n    # Your operational code here\n```\n\n::: zone-end\n\n\n\n## Creating an `AzureAIAgent`\n\nTo create an `AzureAIAgent`, you start by configuring and initializing the agent project through the Azure AI service and then integrate it with Semantic Kernel:\n\n\n\n::: zone pivot=\"programming-language-python\"\n\n```python\nfrom azure.identity.aio import DefaultAzureCredential\nfrom semantic_kernel.agents import AzureAIAgent, AzureAIAgentSettings\n\nai_agent_settings = AzureAIAgentSettings.create()\n\nasync with (\n    DefaultAzureCredential() as creds,\n    AzureAIAgent.create_client(credential=creds) as client,\n):\n    # 1. Define an agent on the Azure AI agent service\n    agent_definition = await client.agents.create_agent(\n        model=ai_agent_settings.model_deployment_name,\n        name=\"<name>\",\n        instructions=\"<instructions>\",\n    )\n\n    # 2. Create a Semantic Kernel agent based on the agent definition\n    agent = AzureAIAgent(\n        client=client,\n        definition=agent_definition,\n    )\n```\n\n::: zone-end\n\n\n\n## Interacting with an `AzureAIAgent`\n\nInteraction with the `AzureAIAgent` is straightforward. The agent maintains the conversation history automatically using a thread.\n\n\n::: zone pivot=\"programming-language-python\"\nThe specifics of the _Azure AI Agent thread_ is abstracted away via the `AzureAIAgentThread` class, which is an implementation of `AgentThread`.\n\n```python\nUSER_INPUTS = [\"Hello\", \"What's your name?\"]\n\nthread: AzureAIAgentThread = AzureAIAgentThread()\n\ntry:\n    for user_input in USER_INPUTS:\n        response = await agent.get_response(messages=user_inputs, thread=thread)\n        print(response)\n        thread = response.thread\nfinally:\n    await thread.delete() if thread else None\n```\n\nOptionally, an agent may be invoked as: \n\n```python\nfor user_input in USER_INPUTS:\n    async for content in agent.invoke(messages=user_input, thread=thread):\n        print(content.content)\n        thread = response.thread\n```\n\nYou may also pass in a list of messages to the `get_response(...)`, `invoke(...)`, or `invoke_stream(...)` methods:\n\n```python\nUSER_INPUTS = [\"Hello\", \"What's your name?\"]\n\nthread: AzureAIAgentThread = AzureAIAgentThread()\n\ntry:\n    for user_input in USER_INPUTS:\n        response = await agent.get_response(messages=USER_INPUTS, thread=thread)\n        print(response)\n        thread = response.thread\nfinally:\n    await thread.delete() if thread else None\n```\n\n::: zone-end\n\nAn agent may also produce a streamed response:\n\n\n\n::: zone pivot=\"programming-language-python\"\n```python\nfor user_input in USER_INPUTS:\n    await agent.add_chat_message(thread_id=thread.id, message=user_input)\n    async for content in agent.invoke_stream(thread_id=thread.id):\n        print(content.content, end=\"\", flush=True)\n```\n::: zone-end\n\n\n\n## Using Plugins with an `AzureAIAgent`\n\nSemantic Kernel supports extending an `AzureAIAgent` with custom plugins for enhanced functionality:\n\n\n\n::: zone pivot=\"programming-language-python\"\n```python\nfrom semantic_kernel.functions import kernel_function\n\nclass SamplePlugin:\n    @kernel_function(description=\"Provides sample data.\")\n    def get_data(self) -> str:\n        return \"Sample data\"\n\nai_agent_settings = AzureAIAgentSettings.create()\n\nasync with (\n        DefaultAzureCredential() as creds,\n        AzureAIAgent.create_client(credential=creds) as client,\n    ):\n        agent_definition = await client.agents.create_agent(\n            model=ai_agent_settings.model_deployment_name,\n        )\n\n        agent = AzureAIAgent(\n            client=client,\n            definition=agent_definition,\n            plugins=[SamplePlugin()]\n        )\n```\n::: zone-end\n\n\n\n## Advanced Features\n\nAn `AzureAIAgent` can leverage advanced tools such as:\n\n- [Code Interpreter](#code-interpreter)\n- [File Search](#file-search)\n- [OpenAPI integration](#openapi-integration)\n- [Azure AI Search integration](#azureai-search-integration)\n\n### Code Interpreter\n\nCode Interpreter allows the agents to write and run Python code in a sandboxed execution environment ([Azure AI Agent Service Code Interpreter](/azure/ai-services/agents/how-to/tools/code-interpreter)).\n\n\n\n::: zone pivot=\"programming-language-python\"\n```python\nfrom azure.ai.projects.models import CodeInterpreterTool\n\nasync with (\n        DefaultAzureCredential() as creds,\n        AzureAIAgent.create_client(credential=creds) as client,\n    ):\n        code_interpreter = CodeInterpreterTool()\n        agent_definition = await client.agents.create_agent(\n            model=ai_agent_settings.model_deployment_name,\n            tools=code_interpreter.definitions,\n            tool_resources=code_interpreter.resources,\n        )\n```\n::: zone-end\n\n\n\n### File Search\n\nFile search augments agents with knowledge from outside its model ([Azure AI Agent Service File Search Tool](/azure/ai-services/agents/how-to/tools/file-search)).\n\n\n\n::: zone pivot=\"programming-language-python\"\n```python\nfrom azure.ai.projects.models import FileSearchTool\n\nasync with (\n        DefaultAzureCredential() as creds,\n        AzureAIAgent.create_client(credential=creds) as client,\n    ):\n        file_search = FileSearchTool(vector_store_ids=[vector_store.id])\n        agent_definition = await client.agents.create_agent(\n            model=ai_agent_settings.model_deployment_name,\n            tools=file_search.definitions,\n            tool_resources=file_search.resources,\n        )\n```\n::: zone-end\n\n\n\n### OpenAPI Integration\n\nConnects your agent to an external API ([How to use Azure AI Agent Service with OpenAPI Specified Tools](/azure/ai-services/agents/how-to/tools/openapi-spec)).\n\n\n\n::: zone pivot=\"programming-language-python\"\n```python\nfrom azure.ai.projects.models import OpenApiTool, OpenApiAnonymousAuthDetails\n\nasync with (\n        DefaultAzureCredential() as creds,\n        AzureAIAgent.create_client(credential=creds) as client,\n    ):\n        openapi_spec_file_path = \"sample/filepath/...\"\n        with open(os.path.join(openapi_spec_file_path, \"spec_one.json\")) as file_one:\n            openapi_spec_one = json.loads(file_one.read())\n        with open(os.path.join(openapi_spec_file_path, \"spec_two.json\")) as file_two:\n            openapi_spec_two = json.loads(file_two.read())\n\n        # Note that connection or managed identity auth setup requires additional setup in Azure\n        auth = OpenApiAnonymousAuthDetails()\n        openapi_tool_one = OpenApiTool(\n            name=\"<name>\",\n            spec=openapi_spec_one,\n            description=\"<description>\",\n            auth=auth,\n        )\n        openapi_tool_two = OpenApiTool(\n            name=\"<name>\",\n            spec=openapi_spec_two,\n            description=\"<description>\",\n            auth=auth,\n        )\n\n        agent_definition = await client.agents.create_agent(\n            model=ai_agent_settings.model_deployment_name,\n            tools=openapi_tool_one.definitions + openapi_tool_two.definitions,\n        )\n```\n::: zone-end\n\n\n\n### AzureAI Search Integration\n\nUse an existing Azure AI Search index with with your agent ([Use an existing AI Search index](/azure/ai-services/agents/how-to/tools/azure-ai-search)).\n\n\n\n::: zone pivot=\"programming-language-python\"\n```python\nfrom azure.ai.projects.models import AzureAISearchTool, ConnectionType\n\nasync with (\n        DefaultAzureCredential() as creds,\n        AzureAIAgent.create_client(credential=creds) as client,\n    ):\n        conn_list = await client.connections.list()\n\n        ai_search_conn_id = \"\"\n        for conn in conn_list:\n            if conn.connection_type == ConnectionType.AZURE_AI_SEARCH:\n                ai_search_conn_id = conn.id\n                break\n\n        ai_search = AzureAISearchTool(\n            index_connection_id=ai_search_conn_id, \n            index_name=AZURE_AI_SEARCH_INDEX_NAME,\n        )\n\n        agent_definition = await client.agents.create_agent(\n            model=ai_agent_settings.model_deployment_name,\n            instructions=\"Answer questions using your index.\",\n            tools=ai_search.definitions,\n            tool_resources=ai_search.resources,\n            headers={\"x-ms-enable-preview\": \"true\"},\n        )\n```\n::: zone-end\n\n\n\n### Retrieving an Existing `AzureAIAgent`\n\nAn existing agent can be retrieved and reused by specifying its assistant ID:\n\n\n\n::: zone pivot=\"programming-language-python\"\n```python\nagent_definition = await client.agents.get_agent(assistant_id=\"your-agent-id\")\nagent = AzureAIAgent(client=client, definition=agent_definition)\n```\n::: zone-end\n\n\n\n## Deleting an `AzureAIAgent`\n\nAgents and their associated threads can be deleted when no longer needed:\n\n\n\n::: zone pivot=\"programming-language-python\"\n```python\nawait client.agents.delete_thread(thread.id)\nawait client.agents.delete_agent(agent.id)\n```\n::: zone-end\n\nIf working with a vector store or files, they may be deleted as well:\n\n\n\n::: zone pivot=\"programming-language-python\"\n```python\nawait client.agents.delete_file(file_id=file.id)\nawait client.agents.delete_vector_store(vector_store_id=vector_store.id)\n```\n::: zone-end\n\n\n\n> More information on the _file search_ tool is described in the [Azure AI Agent Service file search tool](/azure/ai-services/agents/how-to/tools/file-search) article.\n\n## How-To\n\nFor practical examples of using an `AzureAIAgent`, see our code samples on GitHub:\n\n\n\n::: zone pivot=\"programming-language-python\"\n\n- [Getting Started with Azure AI Agents](https://github.com/microsoft/semantic-kernel/tree/main/python/samples/getting_started_with_agents/azure_ai_agent)\n- [Advanced Azure AI Agent Code Samples](https://github.com/microsoft/semantic-kernel/tree/main/python/samples/concepts/agents/azure_ai_agent)\n\n::: zone-end\n\n\n\n## Handling Intermediate Messages with an `AzureAIAgent`\n\nThe Semantic Kernel `AzureAIAgent` is designed to invoke an agent that fulfills user queries or questions. During invocation, the agent may execute tools to derive the final answer. To access intermediate messages produced during this process, callers can supply a callback function that handles instances of `FunctionCallContent` or `FunctionResultContent`.\n\n\n\n::: zone pivot=\"programming-language-python\"\n\nConfiguring the `on_intermediate_message` callback within `agent.invoke(...)` or `agent.invoke_stream(...)` allows the caller to receive intermediate messages generated during the process of formulating the agent's final response.\n\n```python\nimport asyncio\nfrom typing import Annotated\n\nfrom azure.identity.aio import DefaultAzureCredential\n\nfrom semantic_kernel.agents import AzureAIAgent, AzureAIAgentSettings\nfrom semantic_kernel.contents import ChatMessageContent, FunctionCallContent, FunctionResultContent\nfrom semantic_kernel.functions import kernel_function\n\nclass MenuPlugin:\n    \"\"\"A sample Menu Plugin used for the concept sample.\"\"\"\n\n    @kernel_function(description=\"Provides a list of specials from the menu.\")\n    def get_specials(self) -> Annotated[str, \"Returns the specials from the menu.\"]:\n        return \"\"\"\n        Special Soup: Clam Chowder\n        Special Salad: Cobb Salad\n        Special Drink: Chai Tea\n        \"\"\"\n\n    @kernel_function(description=\"Provides the price of the requested menu item.\")\n    def get_item_price(\n        self, menu_item: Annotated[str, \"The name of the menu item.\"]\n    ) -> Annotated[str, \"Returns the price of the menu item.\"]:\n        return \"$9.99\"\n\n# Define a list to hold callback message content\nintermediate_steps: list[ChatMessageContent] = []\n\n# Define an async method to handle the `on_intermediate_message` callback\nasync def handle_intermediate_steps(message: ChatMessageContent) -> None:\n    intermediate_steps.append(message)\n\nasync def main():\n    ai_agent_settings = AzureAIAgentSettings.create()\n\n    async with (\n        DefaultAzureCredential() as creds,\n        AzureAIAgent.create_client(\n            credential=creds,\n            conn_str=ai_agent_settings.project_connection_string.get_secret_value(),\n        ) as client,\n    ):\n        # Create agent definition\n        agent_definition = await client.agents.create_agent(\n            model=ai_agent_settings.model_deployment_name,\n            name=\"<agent-name>\",\n            instructions=\"<agent-instructions>\",\n        )\n\n        # Create the AzureAI Agent\n        agent = AzureAIAgent(\n            client=client,\n            definition=agent_definition,\n            plugins=[MenuPlugin()],\n        )\n\n        user_inputs = [\n            \"Hello\", \n            \"What is the special soup?\", \n            \"What is the special drink?\", \n            \"How much is that?\", \n            \"Thank you\",\n        ]\n\n        thread = None\n\n        # Generate the agent response(s)\n        for user_input in user_inputs:\n            print(f\"# {AuthorRole.USER}: '{user_input}'\")\n            async for response in agent.invoke(\n                messages=user_input,\n                thread=thread,\n                on_intermediate_message=handle_intermediate_steps,\n            ):\n                thread = response.thread\n                print(f\"# {response.name}: {response.content}\")\n\n        # Delete the thread when it is no longer needed\n        await thread.delete() if thread else None\n\n        # Print the intermediate steps\n        print(\"\\nIntermediate Steps:\")\n        for msg in intermediate_steps:\n            if any(isinstance(item, FunctionResultContent) for item in msg.items):\n                for fr in msg.items:\n                    if isinstance(fr, FunctionResultContent):\n                        print(f\"Function Result:> {fr.result} for function: {fr.name}\")\n            elif any(isinstance(item, FunctionCallContent) for item in msg.items):\n                for fcc in msg.items:\n                    if isinstance(fcc, FunctionCallContent):\n                        print(f\"Function Call:> {fcc.name} with arguments: {fcc.arguments}\")\n            else:\n                print(f\"{msg.role}: {msg.content}\")\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n```\n\nThe following demonstrates sample output from the agent invocation process:\n\n```bash\nSample Output:\n\n# AuthorRole.USER: 'Hello'\n# Host: Hi there! How can I assist you with the menu today?\n# AuthorRole.USER: 'What is the special soup?'\n# Host: The special soup is Clam Chowder.\n# AuthorRole.USER: 'What is the special drink?'\n# Host: The special drink is Chai Tea.\n# AuthorRole.USER: 'How much is that?'\n# Host: Could you please specify the menu item you are asking about?\n# AuthorRole.USER: 'Thank you'\n# Host: You're welcome! If you have any questions about the menu or need assistance, feel free to ask.\n\nIntermediate Steps:\nAuthorRole.ASSISTANT: Hi there! How can I assist you with the menu today?\nAuthorRole.ASSISTANT: \nFunction Result:> \n        Special Soup: Clam Chowder\n        Special Salad: Cobb Salad\n        Special Drink: Chai Tea\n        for function: MenuPlugin-get_specials\nAuthorRole.ASSISTANT: The special soup is Clam Chowder.\nAuthorRole.ASSISTANT: \nFunction Result:> \n        Special Soup: Clam Chowder\n        Special Salad: Cobb Salad\n        Special Drink: Chai Tea\n        for function: MenuPlugin-get_specials\nAuthorRole.ASSISTANT: The special drink is Chai Tea.\nAuthorRole.ASSISTANT: Could you please specify the menu item you are asking about?\nAuthorRole.ASSISTANT: You're welcome! If you have any questions about the menu or need assistance, feel free to ask.\n```\n\n::: zone-end\n\n\n\n> [!div class=\"nextstepaction\"]\n> [Explore the OpenAI Responses Agent](./responses-agent.md)",
    "filename": "C:\\Work\\sk\\chainlit-demo\\data\\markdowns\\azure-ai-agent.md",
    "embedding": "Exploring the Semantic Kernel Azure AI Agent Agent - An exploration of the definition, behaviors, and usage patterns for an Azure AI Agent - # Exploring the Semantic Kernel `AzureAIAgent`\n\n> [!IMPORTANT]\n> This feature is in the experimental stage. Features at this stage are under development and subject to change before advancing to the preview or release candidate stage.\n\nDetailed API documentation related to this discussion is available at:\n\n\n\n::: zone pivot=\"programming-language-python\"\n\n- [`AzureAIAgent`](/python/api/semantic-kernel/semantic_kernel.agents.azure_ai.azure_ai_agent.azureaiagent)\n\n::: zone-end\n\n\n\n## What is an `AzureAIAgent`?\n\nAn `AzureAIAgent` is a specialized agent within the Semantic Kernel framework, designed to provide advanced conversational capabilities with seamless tool integration. It automates tool calling, eliminating the need for manual parsing and invocation. The agent also securely manages conversation history using threads, reducing the overhead of maintaining state. Additionally, the `AzureAIAgent` supports a variety of built-in tools, including file retrieval, code execution, and data interaction via Bing, Azure AI Search, Azure Functions, and OpenAPI.\n\nTo use an `AzureAIAgent`, an Azure AI Foundry Project must be utilized.  The following articles provide an overview of the Azure AI Foundry, how to create and configure a project, and the agent service:\n\n- [What is Azure AI Foundry?](/azure/ai-foundry/what-is-ai-foundry)\n- [The Azure AI Foundry SDK](/azure/ai-foundry/how-to/develop/sdk-overview)\n- [What is Azure AI Agent Service](/azure/ai-services/agents/overview)\n- [Quickstart: Create a new agent](/azure/ai-services/agents/quickstart)\n\n\n## Preparing Your Development Environment\n\nTo proceed with developing an `AzureAIAgent`, configure your development environment with the appropriate packages.\n\n\n\n::: zone pivot=\"programming-language-python\"\n\nInstall the `semantic-kernel` package with the optional Azure dependencies:\n\n```bash\npip install semantic-kernel[azure]\n```\n::: zone-end\n\n\n\n\n## Configuring the AI Project Client\n\nAccessing an `AzureAIAgent` first requires the creation of a project client that is configured for a specific Foundry Project, most commonly by providing a connection string ([The Azure AI Foundry SDK: Getting Started with Projects](/azure/ai-foundry/how-to/develop/sdk-overview#get-started-with-projects)).\n\n\n\n::: zone pivot=\"programming-language-python\"\n\nModify your the `.env` file in the root directory to include:\n\n```bash\nAZURE_AI_AGENT_PROJECT_CONNECTION_STRING = \"<example-connection-string>\"\nAZURE_AI_AGENT_MODEL_DEPLOYMENT_NAME = \"<example-model-deployment-name>\"\n```\n\nor\n\n```bash\nAZURE_AI_AGENT_ENDPOINT = \"<example-endpoint>\"\nAZURE_AI_AGENT_SUBSCRIPTION_ID = \"<example-subscription-id>\"\nAZURE_AI_AGENT_RESOURCE_GROUP_NAME = \"<example-resource-group-name>\"\nAZURE_AI_AGENT_PROJECT_NAME = \"<example-project-name>\"\nAZURE_AI_AGENT_MODEL_DEPLOYMENT_NAME = \"<example-model-deployment-name>\"\n```\n\nOnce the configuration is defined, the client may be created:\n\n```python\nfrom semantic_kernel.agents import AzureAIAgent\n\nasync with (\n    DefaultAzureCredential() as creds,\n    AzureAIAgent.create_client(credential=creds) as client,\n):\n    # Your operational code here\n```\n\n::: zone-end\n\n\n\n## Creating an `AzureAIAgent`\n\nTo create an `AzureAIAgent`, you start by configuring and initializing the agent project through the Azure AI service and then integrate it with Semantic Kernel:\n\n\n\n::: zone pivot=\"programming-language-python\"\n\n```python\nfrom azure.identity.aio import DefaultAzureCredential\nfrom semantic_kernel.agents import AzureAIAgent, AzureAIAgentSettings\n\nai_agent_settings = AzureAIAgentSettings.create()\n\nasync with (\n    DefaultAzureCredential() as creds,\n    AzureAIAgent.create_client(credential=creds) as client,\n):\n    # 1. Define an agent on the Azure AI agent service\n    agent_definition = await client.agents.create_agent(\n        model=ai_agent_settings.model_deployment_name,\n        name=\"<name>\",\n        instructions=\"<instructions>\",\n    )\n\n    # 2. Create a Semantic Kernel agent based on the agent definition\n    agent = AzureAIAgent(\n        client=client,\n        definition=agent_definition,\n    )\n```\n\n::: zone-end\n\n\n\n## Interacting with an `AzureAIAgent`\n\nInteraction with the `AzureAIAgent` is straightforward. The agent maintains the conversation history automatically using a thread.\n\n\n::: zone pivot=\"programming-language-python\"\nThe specifics of the _Azure AI Agent thread_ is abstracted away via the `AzureAIAgentThread` class, which is an implementation of `AgentThread`.\n\n```python\nUSER_INPUTS = [\"Hello\", \"What's your name?\"]\n\nthread: AzureAIAgentThread = AzureAIAgentThread()\n\ntry:\n    for user_input in USER_INPUTS:\n        response = await agent.get_response(messages=user_inputs, thread=thread)\n        print(response)\n        thread = response.thread\nfinally:\n    await thread.delete() if thread else None\n```\n\nOptionally, an agent may be invoked as: \n\n```python\nfor user_input in USER_INPUTS:\n    async for content in agent.invoke(messages=user_input, thread=thread):\n        print(content.content)\n        thread = response.thread\n```\n\nYou may also pass in a list of messages to the `get_response(...)`, `invoke(...)`, or `invoke_stream(...)` methods:\n\n```python\nUSER_INPUTS = [\"Hello\", \"What's your name?\"]\n\nthread: AzureAIAgentThread = AzureAIAgentThread()\n\ntry:\n    for user_input in USER_INPUTS:\n        response = await agent.get_response(messages=USER_INPUTS, thread=thread)\n        print(response)\n        thread = response.thread\nfinally:\n    await thread.delete() if thread else None\n```\n\n::: zone-end\n\nAn agent may also produce a streamed response:\n\n\n\n::: zone pivot=\"programming-language-python\"\n```python\nfor user_input in USER_INPUTS:\n    await agent.add_chat_message(thread_id=thread.id, message=user_input)\n    async for content in agent.invoke_stream(thread_id=thread.id):\n        print(content.content, end=\"\", flush=True)\n```\n::: zone-end\n\n\n\n## Using Plugins with an `AzureAIAgent`\n\nSemantic Kernel supports extending an `AzureAIAgent` with custom plugins for enhanced functionality:\n\n\n\n::: zone pivot=\"programming-language-python\"\n```python\nfrom semantic_kernel.functions import kernel_function\n\nclass SamplePlugin:\n    @kernel_function(description=\"Provides sample data.\")\n    def get_data(self) -> str:\n        return \"Sample data\"\n\nai_agent_settings = AzureAIAgentSettings.create()\n\nasync with (\n        DefaultAzureCredential() as creds,\n        AzureAIAgent.create_client(credential=creds) as client,\n    ):\n        agent_definition = await client.agents.create_agent(\n            model=ai_agent_settings.model_deployment_name,\n        )\n\n        agent = AzureAIAgent(\n            client=client,\n            definition=agent_definition,\n            plugins=[SamplePlugin()]\n        )\n```\n::: zone-end\n\n\n\n## Advanced Features\n\nAn `AzureAIAgent` can leverage advanced tools such as:\n\n- [Code Interpreter](#code-interpreter)\n- [File Search](#file-search)\n- [OpenAPI integration](#openapi-integration)\n- [Azure AI Search integration](#azureai-search-integration)\n\n### Code Interpreter\n\nCode Interpreter allows the agents to write and run Python code in a sandboxed execution environment ([Azure AI Agent Service Code Interpreter](/azure/ai-services/agents/how-to/tools/code-interpreter)).\n\n\n\n::: zone pivot=\"programming-language-python\"\n```python\nfrom azure.ai.projects.models import CodeInterpreterTool\n\nasync with (\n        DefaultAzureCredential() as creds,\n        AzureAIAgent.create_client(credential=creds) as client,\n    ):\n        code_interpreter = CodeInterpreterTool()\n        agent_definition = await client.agents.create_agent(\n            model=ai_agent_settings.model_deployment_name,\n            tools=code_interpreter.definitions,\n            tool_resources=code_interpreter.resources,\n        )\n```\n::: zone-end\n\n\n\n### File Search\n\nFile search augments agents with knowledge from outside its model ([Azure AI Agent Service File Search Tool](/azure/ai-services/agents/how-to/tools/file-search)).\n\n\n\n::: zone pivot=\"programming-language-python\"\n```python\nfrom azure.ai.projects.models import FileSearchTool\n\nasync with (\n        DefaultAzureCredential() as creds,\n        AzureAIAgent.create_client(credential=creds) as client,\n    ):\n        file_search = FileSearchTool(vector_store_ids=[vector_store.id])\n        agent_definition = await client.agents.create_agent(\n            model=ai_agent_settings.model_deployment_name,\n            tools=file_search.definitions,\n            tool_resources=file_search.resources,\n        )\n```\n::: zone-end\n\n\n\n### OpenAPI Integration\n\nConnects your agent to an external API ([How to use Azure AI Agent Service with OpenAPI Specified Tools](/azure/ai-services/agents/how-to/tools/openapi-spec)).\n\n\n\n::: zone pivot=\"programming-language-python\"\n```python\nfrom azure.ai.projects.models import OpenApiTool, OpenApiAnonymousAuthDetails\n\nasync with (\n        DefaultAzureCredential() as creds,\n        AzureAIAgent.create_client(credential=creds) as client,\n    ):\n        openapi_spec_file_path = \"sample/filepath/...\"\n        with open(os.path.join(openapi_spec_file_path, \"spec_one.json\")) as file_one:\n            openapi_spec_one = json.loads(file_one.read())\n        with open(os.path.join(openapi_spec_file_path, \"spec_two.json\")) as file_two:\n            openapi_spec_two = json.loads(file_two.read())\n\n        # Note that connection or managed identity auth setup requires additional setup in Azure\n        auth = OpenApiAnonymousAuthDetails()\n        openapi_tool_one = OpenApiTool(\n            name=\"<name>\",\n            spec=openapi_spec_one,\n            description=\"<description>\",\n            auth=auth,\n        )\n        openapi_tool_two = OpenApiTool(\n            name=\"<name>\",\n            spec=openapi_spec_two,\n            description=\"<description>\",\n            auth=auth,\n        )\n\n        agent_definition = await client.agents.create_agent(\n            model=ai_agent_settings.model_deployment_name,\n            tools=openapi_tool_one.definitions + openapi_tool_two.definitions,\n        )\n```\n::: zone-end\n\n\n\n### AzureAI Search Integration\n\nUse an existing Azure AI Search index with with your agent ([Use an existing AI Search index](/azure/ai-services/agents/how-to/tools/azure-ai-search)).\n\n\n\n::: zone pivot=\"programming-language-python\"\n```python\nfrom azure.ai.projects.models import AzureAISearchTool, ConnectionType\n\nasync with (\n        DefaultAzureCredential() as creds,\n        AzureAIAgent.create_client(credential=creds) as client,\n    ):\n        conn_list = await client.connections.list()\n\n        ai_search_conn_id = \"\"\n        for conn in conn_list:\n            if conn.connection_type == ConnectionType.AZURE_AI_SEARCH:\n                ai_search_conn_id = conn.id\n                break\n\n        ai_search = AzureAISearchTool(\n            index_connection_id=ai_search_conn_id, \n            index_name=AZURE_AI_SEARCH_INDEX_NAME,\n        )\n\n        agent_definition = await client.agents.create_agent(\n            model=ai_agent_settings.model_deployment_name,\n            instructions=\"Answer questions using your index.\",\n            tools=ai_search.definitions,\n            tool_resources=ai_search.resources,\n            headers={\"x-ms-enable-preview\": \"true\"},\n        )\n```\n::: zone-end\n\n\n\n### Retrieving an Existing `AzureAIAgent`\n\nAn existing agent can be retrieved and reused by specifying its assistant ID:\n\n\n\n::: zone pivot=\"programming-language-python\"\n```python\nagent_definition = await client.agents.get_agent(assistant_id=\"your-agent-id\")\nagent = AzureAIAgent(client=client, definition=agent_definition)\n```\n::: zone-end\n\n\n\n## Deleting an `AzureAIAgent`\n\nAgents and their associated threads can be deleted when no longer needed:\n\n\n\n::: zone pivot=\"programming-language-python\"\n```python\nawait client.agents.delete_thread(thread.id)\nawait client.agents.delete_agent(agent.id)\n```\n::: zone-end\n\nIf working with a vector store or files, they may be deleted as well:\n\n\n\n::: zone pivot=\"programming-language-python\"\n```python\nawait client.agents.delete_file(file_id=file.id)\nawait client.agents.delete_vector_store(vector_store_id=vector_store.id)\n```\n::: zone-end\n\n\n\n> More information on the _file search_ tool is described in the [Azure AI Agent Service file search tool](/azure/ai-services/agents/how-to/tools/file-search) article.\n\n## How-To\n\nFor practical examples of using an `AzureAIAgent`, see our code samples on GitHub:\n\n\n\n::: zone pivot=\"programming-language-python\"\n\n- [Getting Started with Azure AI Agents](https://github.com/microsoft/semantic-kernel/tree/main/python/samples/getting_started_with_agents/azure_ai_agent)\n- [Advanced Azure AI Agent Code Samples](https://github.com/microsoft/semantic-kernel/tree/main/python/samples/concepts/agents/azure_ai_agent)\n\n::: zone-end\n\n\n\n## Handling Intermediate Messages with an `AzureAIAgent`\n\nThe Semantic Kernel `AzureAIAgent` is designed to invoke an agent that fulfills user queries or questions. During invocation, the agent may execute tools to derive the final answer. To access intermediate messages produced during this process, callers can supply a callback function that handles instances of `FunctionCallContent` or `FunctionResultContent`.\n\n\n\n::: zone pivot=\"programming-language-python\"\n\nConfiguring the `on_intermediate_message` callback within `agent.invoke(...)` or `agent.invoke_stream(...)` allows the caller to receive intermediate messages generated during the process of formulating the agent's final response.\n\n```python\nimport asyncio\nfrom typing import Annotated\n\nfrom azure.identity.aio import DefaultAzureCredential\n\nfrom semantic_kernel.agents import AzureAIAgent, AzureAIAgentSettings\nfrom semantic_kernel.contents import ChatMessageContent, FunctionCallContent, FunctionResultContent\nfrom semantic_kernel.functions import kernel_function\n\nclass MenuPlugin:\n    \"\"\"A sample Menu Plugin used for the concept sample.\"\"\"\n\n    @kernel_function(description=\"Provides a list of specials from the menu.\")\n    def get_specials(self) -> Annotated[str, \"Returns the specials from the menu.\"]:\n        return \"\"\"\n        Special Soup: Clam Chowder\n        Special Salad: Cobb Salad\n        Special Drink: Chai Tea\n        \"\"\"\n\n    @kernel_function(description=\"Provides the price of the requested menu item.\")\n    def get_item_price(\n        self, menu_item: Annotated[str, \"The name of the menu item.\"]\n    ) -> Annotated[str, \"Returns the price of the menu item.\"]:\n        return \"$9.99\"\n\n# Define a list to hold callback message content\nintermediate_steps: list[ChatMessageContent] = []\n\n# Define an async method to handle the `on_intermediate_message` callback\nasync def handle_intermediate_steps(message: ChatMessageContent) -> None:\n    intermediate_steps.append(message)\n\nasync def main():\n    ai_agent_settings = AzureAIAgentSettings.create()\n\n    async with (\n        DefaultAzureCredential() as creds,\n        AzureAIAgent.create_client(\n            credential=creds,\n            conn_str=ai_agent_settings.project_connection_string.get_secret_value(),\n        ) as client,\n    ):\n        # Create agent definition\n        agent_definition = await client.agents.create_agent(\n            model=ai_agent_settings.model_deployment_name,\n            name=\"<agent-name>\",\n            instructions=\"<agent-instructions>\",\n        )\n\n        # Create the AzureAI Agent\n        agent = AzureAIAgent(\n            client=client,\n            definition=agent_definition,\n            plugins=[MenuPlugin()],\n        )\n\n        user_inputs = [\n            \"Hello\", \n            \"What is the special soup?\", \n            \"What is the special drink?\", \n            \"How much is that?\", \n            \"Thank you\",\n        ]\n\n        thread = None\n\n        # Generate the agent response(s)\n        for user_input in user_inputs:\n            print(f\"# {AuthorRole.USER}: '{user_input}'\")\n            async for response in agent.invoke(\n                messages=user_input,\n                thread=thread,\n                on_intermediate_message=handle_intermediate_steps,\n            ):\n                thread = response.thread\n                print(f\"# {response.name}: {response.content}\")\n\n        # Delete the thread when it is no longer needed\n        await thread.delete() if thread else None\n\n        # Print the intermediate steps\n        print(\"\\nIntermediate Steps:\")\n        for msg in intermediate_steps:\n            if any(isinstance(item, FunctionResultContent) for item in msg.items):\n                for fr in msg.items:\n                    if isinstance(fr, FunctionResultContent):\n                        print(f\"Function Result:> {fr.result} for function: {fr.name}\")\n            elif any(isinstance(item, FunctionCallContent) for item in msg.items):\n                for fcc in msg.items:\n                    if isinstance(fcc, FunctionCallContent):\n                        print(f\"Function Call:> {fcc.name} with arguments: {fcc.arguments}\")\n            else:\n                print(f\"{msg.role}: {msg.content}\")\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n```\n\nThe following demonstrates sample output from the agent invocation process:\n\n```bash\nSample Output:\n\n# AuthorRole.USER: 'Hello'\n# Host: Hi there! How can I assist you with the menu today?\n# AuthorRole.USER: 'What is the special soup?'\n# Host: The special soup is Clam Chowder.\n# AuthorRole.USER: 'What is the special drink?'\n# Host: The special drink is Chai Tea.\n# AuthorRole.USER: 'How much is that?'\n# Host: Could you please specify the menu item you are asking about?\n# AuthorRole.USER: 'Thank you'\n# Host: You're welcome! If you have any questions about the menu or need assistance, feel free to ask.\n\nIntermediate Steps:\nAuthorRole.ASSISTANT: Hi there! How can I assist you with the menu today?\nAuthorRole.ASSISTANT: \nFunction Result:> \n        Special Soup: Clam Chowder\n        Special Salad: Cobb Salad\n        Special Drink: Chai Tea\n        for function: MenuPlugin-get_specials\nAuthorRole.ASSISTANT: The special soup is Clam Chowder.\nAuthorRole.ASSISTANT: \nFunction Result:> \n        Special Soup: Clam Chowder\n        Special Salad: Cobb Salad\n        Special Drink: Chai Tea\n        for function: MenuPlugin-get_specials\nAuthorRole.ASSISTANT: The special drink is Chai Tea.\nAuthorRole.ASSISTANT: Could you please specify the menu item you are asking about?\nAuthorRole.ASSISTANT: You're welcome! If you have any questions about the menu or need assistance, feel free to ask.\n```\n\n::: zone-end\n\n\n\n> [!div class=\"nextstepaction\"]\n> [Explore the OpenAI Responses Agent](./responses-agent.md)"
}
{
    "title": "How to build your own Vector Store connector (Preview)",
    "description": "Describes how to build your own Vector Store connector connector",
    "author": "westey-m",
    "content": "# How to build your own Vector Store connector (Preview)\n\n> [!WARNING]\n> The Semantic Kernel Vector Store functionality is in preview, and improvements that require breaking changes may still occur in limited circumstances before release.\n\n\n::: zone pivot=\"programming-language-python\"\n\nThis article provides guidance for anyone who wishes to build their own Vector Store connector.\nThis article can be used by database providers who wish to build and maintain their own implementation,\nor for anyone who wishes to build and maintain an unofficial connector for a database that lacks support.\n\nIf you wish to contribute your connector to the Semantic Kernel code base:\n\n1. Create an issue in the [Semantic Kernel Github repository](https://github.com/microsoft/semantic-kernel/issues).\n1. Review the [Semantic Kernel contribution guidelines](https://github.com/microsoft/semantic-kernel/blob/main/CONTRIBUTING.md).\n\n## Overview\n\nVector Store connectors are implementations of the [Vector Store base classes](https://github.com/microsoft/semantic-kernel/tree/main/python/semantic_kernel/data/vector_storage) and optionally the [Vector Search base class and methods](https://github.com/microsoft/semantic-kernel/tree/main/python/semantic_kernel/data/vector_search). Some of the decisions that\nwere made when designing the Vector Store abstraction mean that a Vector Store connector requires certain\nfeatures to provide users with a good experience.\n\nA key design decision is that the Vector Store abstraction takes a strongly typed approach to working with database records.\nThis means that `upsert` takes a strongly typed record as input, while `get` returns a strongly typed record.\nThe design uses python generics to achieve the strong typing.\nThis means that a connector has to be able to map from this data model to the storage model used by the underlying database.\nIt also means that a connector may need to find out certain information about the record properties in order to know how\nto map each of these properties. E.g. some vector databases (such as Chroma, Qdrant and Weaviate) require vectors to be stored in a specific structure and non-vectors\nin a different structure, or require record keys to be stored in a specific field.\n\nAt the same time, the Vector Store classes also provides a generic data model that allows a developer to work\nwith a database without needing to create a custom data model.\n\nIt is important for connectors to support different types of model and provide developers with flexibility around\nhow they use the connector. The following section deep dives into each of these requirements.\n\n## Requirements\n\nIn order to be considered a full implementation of the Vector Store abstractions, the following set of requirements must be met.\n\n### Implement the core classes\n\nThe two core classes that need to be implemented are:\n1. VectorStore\n1. VectorStoreRecordCollection[TKey, TModel] or VectorSearchBase[TKey, TModel] (VectorSearchBase is a subclass of VectorStoreRecordCollection)\n\nThen when using VectorSearchBase, the following mixins can be used, at least one otherwise search is not available:\n\n1. VectorTextSearchMixin[TModel]\n1. VectorizableTextSearchMixin[TModel]\n1. VectorizedSearchMixin[TModel]\n\nThe naming convention should be:\n- {database type}VectorStore\n- {database type}VectorStoreRecordCollection or {database type}Collection\n\nE.g.\n- MyDBVectorStore\n- MyDBVectorStoreRecordCollection or MyDBCollection\n\nA `VectorStoreRecordCollection` is tied to a specific collection/index name in the database, that collection name should be passed to the constructor, or the `get_collection` method of the VectorStore.\n\nThese are the methods that need to be implemented:\n\n1. VectorStore\n   1. `VectorStore.get_collection` - This is a factory method that should return a new instance of the VectorStoreRecordCollection for the given collection name, it should not do checks to verify whether a collection exists or not. It should also store the collection in the internal dict `vector_record_collections` so that it can be retrieved later.\n   1. `VectorStore.list_collection_names` - This method should return a list of collection names that are available in the database.\n1. VectorStoreRecordCollection\n   1. `VectorStoreRecordCollection._inner_upsert` - This method takes a list of records and returns a list of keys that were updated or inserted, this method is called from the `upsert` and `upsert_batch` methods, those methods takes care of serialization.\n   2. `VectorStoreRecordCollection._inner_get` - This method takes a list of keys and returns a list of records, this method is called from the `get` and `get_batch` methods.\n   3. `VectorStoreRecordCollection._inner_delete` - This method takes a list of keys and deletes them from the database, this method is called from the `delete` and `delete_batch` methods.\n   4. `VectorStoreRecordCollection._serialize_dicts_to_store_models` - This method takes a list of dicts and returns a list of objects ready to be upserted, this method is called from the `upsert` and `upsert_batch` methods, check the [Serialization docs for more info](../serialization.md).\n   5. `VectorStoreRecordCollection._deserialize_store_models_to_dicts` - This method takes a list of objects from the store and returns a list of dicts, this method is called from the `get`, `get_batch` and optionally `search` methods, check the [Serialization docs for more info](../serialization.md)\n   6. `VectorStoreRecordCollection.create_collection` - This method should create a collection/index in the database, it should be able to parse a `VectorStoreRecordDefinition` and create the collection/index accordingly and also allow the user to supply their own definition, ready for that store, this allows the user to leverage every feature of the store, even ones we don't.\n   7. `VectorStoreRecordCollection.does_collection_exist` - This method should return a boolean indicating whether the collection exists or not.\n   8. `VectorStoreRecordCollection.delete_collection` - This method should delete the collection/index from the database.\n2. VectorSearchBase\n   1. `VectorSearchBase._inner_search` - This method should take the options, query text or vector and `KernelSearchResults` with a `VectorSearchResult` as the internal content, the `KernelSearchResults` is a Async Iterable to allow support for paging results, as search can return a large number of results (there is a helper util to take a list of results and return a `AsyncIterable`).\n   2. `VectorSearchBase._get_record_from_result` - This method should take the search result from the store and extract the actual content, this can also be as simple as returning the result.\n   3. `VectorSearchBase._get_score_from_result` - This method should take the search result from the store and extract the score, this is not always present as some databases don't return a score.\n\nSome other optional items that can be implemented are:\n1. `VectorStoreRecordCollection._validate_data_model` - This method validates the data model, there is a default implementation that takes the `VectorStoreRecordDefinition` and validates the data model against it, with the values from the supported types (see below), but this can be overwritten to provide custom validation. A additional step can be added by doing `super()._validate_data_model()` to run the default validation first.\n1. `VectorStoreRecordCollection.supported_key_types` - This is a `classvar`, that should be a list of supported key types, this is used to validate the key type when creating a collection.\n2. `VectorStoreRecordCollection.supported_vector_types` - This is a `classvar`, that should be a list of supported vector types, this is used to validate the vector type when creating a collection.\n3. `Vector...__aenter__` and `Vector...__aexit__` - These methods should be implemented to allow the use of the `async with` statement, this is useful for managing connections and resources.\n4. `Vector...managed_client` - This is a helper property that can be used to indicate whether the current instance is managing the client or not, this is useful for the `__aenter__` and `__aexit__` methods and should be set based on the constructor arguments.\n5. `VectorSearchBase.options_class` - This is a property that returns the search options class, by default this is the `VectorSearchOptions` but can be overwritten to provide a custom options class. The public methods perform a check of the options type and do a cast if needed.\n\n### Collection / Index Creation\nEvery store has it's own quirks when it comes to the way indexes/collections are defined and which features are supported. Most implementation use some kind of helper or util function to parse the `VectorStoreRecordDefinition` and create the collection/index definition. This includes mapping from the Semantic Kernel IndexKind and DistanceFunction to the store specific ones, and raising an error when a unsupported index or distance function is used. It is advised to use a dict to map between these so that it is easy to update and maintain over time.\n\nThere are features in Semantic Kernel that are not available in the store and vice versa, for instance a data field might be marked as full text searchable in Semantic Kernel but the store might not make that distinction, in this case that setting is ignored. The inverse where there are settings available in the store but not in Semantic Kernel, a sensible default, with a clear docstring or comment on why that default is chosen, should be used and this is exactly the type of thing that a user might want to leverage the break glass feature for (supplying their own definition to the `create_collection` method).\n\n### Exceptions\nMost exceptions are raised with the Semantic Kernel specific types by the public methods, so the developer of the connector should not worry about it, this also makes sure that a user does not have to think about very specific exceptions from each connector. You should also not catch things only to re-raise, that is done once so that the stack trace does not become overly long.\n\nThe vector store exceptions are all coming from the [vector_store_exceptions](https://github.com/microsoft/semantic-kernel/blob/main/python/semantic_kernel/exceptions/vector_store_exceptions.py).\n\n### Batching\nEach store and their client offers different methods and ways of working, we noticed that most either have a batch operation or it has both a single and batch operations, the only one that should be used in Semantic Kernel is the batch one because each of the _inner methods are called with a sequence of keys or records, this is to ensure that the store can optimize the operation as much as possible, without doubling the amount of code. This does mean that sometimes the _inner method will have to batch itself, this should then be done using `asyncio.gather` to ensure that the operations are done in parallel.\n\n::: zone-end\n\n\n## Documentation\n\nTo share the features and limitations of your implementation, you can contribute a documentation page to this\nMicrosoft Learn website. See [here](../out-of-the-box-connectors/index.md)\nfor the documentation on the existing connectors.\n\nTo create your page, create a pull request on the [Semantic Kernel docs Github repository](https://github.com/MicrosoftDocs/semantic-kernel-docs).\nUse the pages in the following folder as examples: [Out-of-the-box connectors](https://github.com/MicrosoftDocs/semantic-kernel-docs/tree/main/semantic-kernel/concepts/vector-store-connectors/out-of-the-box-connectors)\n\nAreas to cover:\n\n1. An `Overview` with a standard table describing the main features of the connector.\n1. An optional `Limitations` section with any limitations for your connector.\n1. A `Getting started` section that describes how to import your nuget and construct your `VectorStore` and `VectorStoreRecordCollection`\n1. A `Data mapping` section showing the connector's default data mapping mechanism to the database storage model, including any property renaming it may support.\n1. Information about additional features your connector supports.",
    "filename": "C:\\Work\\sk\\chainlit-demo\\data\\markdowns\\build-your-own-connector.md",
    "embedding": "How to build your own Vector Store connector (Preview) - Describes how to build your own Vector Store connector connector - # How to build your own Vector Store connector (Preview)\n\n> [!WARNING]\n> The Semantic Kernel Vector Store functionality is in preview, and improvements that require breaking changes may still occur in limited circumstances before release.\n\n\n::: zone pivot=\"programming-language-python\"\n\nThis article provides guidance for anyone who wishes to build their own Vector Store connector.\nThis article can be used by database providers who wish to build and maintain their own implementation,\nor for anyone who wishes to build and maintain an unofficial connector for a database that lacks support.\n\nIf you wish to contribute your connector to the Semantic Kernel code base:\n\n1. Create an issue in the [Semantic Kernel Github repository](https://github.com/microsoft/semantic-kernel/issues).\n1. Review the [Semantic Kernel contribution guidelines](https://github.com/microsoft/semantic-kernel/blob/main/CONTRIBUTING.md).\n\n## Overview\n\nVector Store connectors are implementations of the [Vector Store base classes](https://github.com/microsoft/semantic-kernel/tree/main/python/semantic_kernel/data/vector_storage) and optionally the [Vector Search base class and methods](https://github.com/microsoft/semantic-kernel/tree/main/python/semantic_kernel/data/vector_search). Some of the decisions that\nwere made when designing the Vector Store abstraction mean that a Vector Store connector requires certain\nfeatures to provide users with a good experience.\n\nA key design decision is that the Vector Store abstraction takes a strongly typed approach to working with database records.\nThis means that `upsert` takes a strongly typed record as input, while `get` returns a strongly typed record.\nThe design uses python generics to achieve the strong typing.\nThis means that a connector has to be able to map from this data model to the storage model used by the underlying database.\nIt also means that a connector may need to find out certain information about the record properties in order to know how\nto map each of these properties. E.g. some vector databases (such as Chroma, Qdrant and Weaviate) require vectors to be stored in a specific structure and non-vectors\nin a different structure, or require record keys to be stored in a specific field.\n\nAt the same time, the Vector Store classes also provides a generic data model that allows a developer to work\nwith a database without needing to create a custom data model.\n\nIt is important for connectors to support different types of model and provide developers with flexibility around\nhow they use the connector. The following section deep dives into each of these requirements.\n\n## Requirements\n\nIn order to be considered a full implementation of the Vector Store abstractions, the following set of requirements must be met.\n\n### Implement the core classes\n\nThe two core classes that need to be implemented are:\n1. VectorStore\n1. VectorStoreRecordCollection[TKey, TModel] or VectorSearchBase[TKey, TModel] (VectorSearchBase is a subclass of VectorStoreRecordCollection)\n\nThen when using VectorSearchBase, the following mixins can be used, at least one otherwise search is not available:\n\n1. VectorTextSearchMixin[TModel]\n1. VectorizableTextSearchMixin[TModel]\n1. VectorizedSearchMixin[TModel]\n\nThe naming convention should be:\n- {database type}VectorStore\n- {database type}VectorStoreRecordCollection or {database type}Collection\n\nE.g.\n- MyDBVectorStore\n- MyDBVectorStoreRecordCollection or MyDBCollection\n\nA `VectorStoreRecordCollection` is tied to a specific collection/index name in the database, that collection name should be passed to the constructor, or the `get_collection` method of the VectorStore.\n\nThese are the methods that need to be implemented:\n\n1. VectorStore\n   1. `VectorStore.get_collection` - This is a factory method that should return a new instance of the VectorStoreRecordCollection for the given collection name, it should not do checks to verify whether a collection exists or not. It should also store the collection in the internal dict `vector_record_collections` so that it can be retrieved later.\n   1. `VectorStore.list_collection_names` - This method should return a list of collection names that are available in the database.\n1. VectorStoreRecordCollection\n   1. `VectorStoreRecordCollection._inner_upsert` - This method takes a list of records and returns a list of keys that were updated or inserted, this method is called from the `upsert` and `upsert_batch` methods, those methods takes care of serialization.\n   2. `VectorStoreRecordCollection._inner_get` - This method takes a list of keys and returns a list of records, this method is called from the `get` and `get_batch` methods.\n   3. `VectorStoreRecordCollection._inner_delete` - This method takes a list of keys and deletes them from the database, this method is called from the `delete` and `delete_batch` methods.\n   4. `VectorStoreRecordCollection._serialize_dicts_to_store_models` - This method takes a list of dicts and returns a list of objects ready to be upserted, this method is called from the `upsert` and `upsert_batch` methods, check the [Serialization docs for more info](../serialization.md).\n   5. `VectorStoreRecordCollection._deserialize_store_models_to_dicts` - This method takes a list of objects from the store and returns a list of dicts, this method is called from the `get`, `get_batch` and optionally `search` methods, check the [Serialization docs for more info](../serialization.md)\n   6. `VectorStoreRecordCollection.create_collection` - This method should create a collection/index in the database, it should be able to parse a `VectorStoreRecordDefinition` and create the collection/index accordingly and also allow the user to supply their own definition, ready for that store, this allows the user to leverage every feature of the store, even ones we don't.\n   7. `VectorStoreRecordCollection.does_collection_exist` - This method should return a boolean indicating whether the collection exists or not.\n   8. `VectorStoreRecordCollection.delete_collection` - This method should delete the collection/index from the database.\n2. VectorSearchBase\n   1. `VectorSearchBase._inner_search` - This method should take the options, query text or vector and `KernelSearchResults` with a `VectorSearchResult` as the internal content, the `KernelSearchResults` is a Async Iterable to allow support for paging results, as search can return a large number of results (there is a helper util to take a list of results and return a `AsyncIterable`).\n   2. `VectorSearchBase._get_record_from_result` - This method should take the search result from the store and extract the actual content, this can also be as simple as returning the result.\n   3. `VectorSearchBase._get_score_from_result` - This method should take the search result from the store and extract the score, this is not always present as some databases don't return a score.\n\nSome other optional items that can be implemented are:\n1. `VectorStoreRecordCollection._validate_data_model` - This method validates the data model, there is a default implementation that takes the `VectorStoreRecordDefinition` and validates the data model against it, with the values from the supported types (see below), but this can be overwritten to provide custom validation. A additional step can be added by doing `super()._validate_data_model()` to run the default validation first.\n1. `VectorStoreRecordCollection.supported_key_types` - This is a `classvar`, that should be a list of supported key types, this is used to validate the key type when creating a collection.\n2. `VectorStoreRecordCollection.supported_vector_types` - This is a `classvar`, that should be a list of supported vector types, this is used to validate the vector type when creating a collection.\n3. `Vector...__aenter__` and `Vector...__aexit__` - These methods should be implemented to allow the use of the `async with` statement, this is useful for managing connections and resources.\n4. `Vector...managed_client` - This is a helper property that can be used to indicate whether the current instance is managing the client or not, this is useful for the `__aenter__` and `__aexit__` methods and should be set based on the constructor arguments.\n5. `VectorSearchBase.options_class` - This is a property that returns the search options class, by default this is the `VectorSearchOptions` but can be overwritten to provide a custom options class. The public methods perform a check of the options type and do a cast if needed.\n\n### Collection / Index Creation\nEvery store has it's own quirks when it comes to the way indexes/collections are defined and which features are supported. Most implementation use some kind of helper or util function to parse the `VectorStoreRecordDefinition` and create the collection/index definition. This includes mapping from the Semantic Kernel IndexKind and DistanceFunction to the store specific ones, and raising an error when a unsupported index or distance function is used. It is advised to use a dict to map between these so that it is easy to update and maintain over time.\n\nThere are features in Semantic Kernel that are not available in the store and vice versa, for instance a data field might be marked as full text searchable in Semantic Kernel but the store might not make that distinction, in this case that setting is ignored. The inverse where there are settings available in the store but not in Semantic Kernel, a sensible default, with a clear docstring or comment on why that default is chosen, should be used and this is exactly the type of thing that a user might want to leverage the break glass feature for (supplying their own definition to the `create_collection` method).\n\n### Exceptions\nMost exceptions are raised with the Semantic Kernel specific types by the public methods, so the developer of the connector should not worry about it, this also makes sure that a user does not have to think about very specific exceptions from each connector. You should also not catch things only to re-raise, that is done once so that the stack trace does not become overly long.\n\nThe vector store exceptions are all coming from the [vector_store_exceptions](https://github.com/microsoft/semantic-kernel/blob/main/python/semantic_kernel/exceptions/vector_store_exceptions.py).\n\n### Batching\nEach store and their client offers different methods and ways of working, we noticed that most either have a batch operation or it has both a single and batch operations, the only one that should be used in Semantic Kernel is the batch one because each of the _inner methods are called with a sequence of keys or records, this is to ensure that the store can optimize the operation as much as possible, without doubling the amount of code. This does mean that sometimes the _inner method will have to batch itself, this should then be done using `asyncio.gather` to ensure that the operations are done in parallel.\n\n::: zone-end\n\n\n## Documentation\n\nTo share the features and limitations of your implementation, you can contribute a documentation page to this\nMicrosoft Learn website. See [here](../out-of-the-box-connectors/index.md)\nfor the documentation on the existing connectors.\n\nTo create your page, create a pull request on the [Semantic Kernel docs Github repository](https://github.com/MicrosoftDocs/semantic-kernel-docs).\nUse the pages in the following folder as examples: [Out-of-the-box connectors](https://github.com/MicrosoftDocs/semantic-kernel-docs/tree/main/semantic-kernel/concepts/vector-store-connectors/out-of-the-box-connectors)\n\nAreas to cover:\n\n1. An `Overview` with a standard table describing the main features of the connector.\n1. An optional `Limitations` section with any limitations for your connector.\n1. A `Getting started` section that describes how to import your nuget and construct your `VectorStore` and `VectorStoreRecordCollection`\n1. A `Data mapping` section showing the connector's default data mapping mechanism to the database storage model, including any property renaming it may support.\n1. Information about additional features your connector supports."
}
{
    "title": "Exploring the Semantic Kernel ChatCompletionAgent",
    "description": "An exploration of the definition, behaviors, and usage patterns for a Chat Completion Agent",
    "author": "crickman",
    "content": "# Exploring the Semantic Kernel `ChatCompletionAgent`\n\nDetailed API documentation related to this discussion is available at:\n\n\n\n::: zone pivot=\"programming-language-python\"\n\n- [`ChatCompletionAgent`](/python/api/semantic-kernel/semantic_kernel.agents.chat_completion.chat_completion_agent.chatcompletionagent)\n\n::: zone-end\n\n\n\n## Chat Completion in Semantic Kernel\n\n[Chat Completion](../../concepts/ai-services/chat-completion/index.md) is fundamentally a protocol for a chat-based interaction with an AI model where the chat-history is maintained and presented to the model with each request.  Semantic Kernel [AI services](../../concepts/ai-services/index.md) offer a unified framework for integrating the chat-completion capabilities of various AI models.\n\nA `ChatCompletionAgent` can leverage any of these [AI services](../../concepts/ai-services/chat-completion/index.md) to generate responses, whether directed to a user or another agent.\n\n## Preparing Your Development Environment\n\nTo proceed with developing an `ChatCompletionAgent`, configure your development environment with the appropriate packages.\n\n\n\n::: zone pivot=\"programming-language-python\"\n\nInstall the `semantic-kernel` package:\n\n```bash\npip install semantic-kernel\n```\n\n> [!IMPORTANT]\n> Depending upon which AI Service you use as part of the `ChatCompletionAgent`, you may need to install extra packages. Please check for the required extra on the following [page](../../concepts/ai-services/chat-completion/index.md#creating-a-chat-completion-service)\n\n\n::: zone-end\n\n\n\n## Creating a `ChatCompletionAgent`\n\nA `ChatCompletionAgent` is fundamentally based on an [AI services](../../concepts/ai-services/index.md).  As such, creating a `ChatCompletionAgent` starts with creating a [`Kernel`](../../concepts/kernel.md) instance that contains one or more chat-completion services and then instantiating the agent with a reference to that [`Kernel`](../../concepts/kernel.md) instance.\n\n\n\n::: zone pivot=\"programming-language-python\"\nThere are two ways to create a `ChatCompletionAgent`:\n\n### 1. By providing the chat completion service directly\n\n```python\nfrom semantic_kernel.agents import ChatCompletionAgent\n\n# Create the agent by directly providing the chat completion service\nagent = ChatCompletionAgent(\n    service=AzureChatCompletion(),  # your chat completion service instance\n    name=\"<agent name>\",\n    instructions=\"<agent instructions>\",\n)\n```\n\n### 2. By creating a Kernel first, adding the service to it, then providing the kernel\n\n```python\n# Define the kernel\nkernel = Kernel()\n\n# Add the chat completion service to the kernel\nkernel.add_service(AzureChatCompletion())\n\n# Create the agent using the kernel\nagent = ChatCompletionAgent(\n  kernel=kernel, \n  name=\"<agent name>\", \n  instructions=\"<agent instructions>\",\n)\n```\n\nThe first method is useful when you already have a chat completion service ready. The second method is beneficial when you need a kernel that manages multiple services or additional functionalities.\n::: zone-end\n\n\n\n## AI Service Selection\n\nNo different from using Semantic Kernel [AI services](../../concepts/ai-services/index.md) directly, a `ChatCompletionAgent` supports the specification of a service-selector.  A service-selector identifies which [AI service](../../concepts/ai-services/index.md) to target when the [`Kernel`](../../concepts/kernel.md) contains more than one.\n\n> Note: If multiple [AI services](../../concepts/ai-services/index.md) are present and no service-selector is provided, the same default logic is applied for the agent that you'd find when using an [AI services](../../concepts/ai-services/index.md) outside of the `Agent Framework`\n\n\n\n::: zone pivot=\"programming-language-python\"\n\n```python\nfrom semantic_kernel.connectors.ai.open_ai import (\n    AzureChatCompletion,\n    AzureChatPromptExecutionSettings,\n)\n\n# Define the Kernel\nkernel = Kernel()\n\n# Add the AzureChatCompletion AI Service to the Kernel\nkernel.add_service(AzureChatCompletion(service_id=\"service1\"))\nkernel.add_service(AzureChatCompletion(service_id=\"service2\"))\n\nsettings = AzureChatPromptExecutionSettings(service_id=\"service2\")\n\n# Create the agent\nagent = ChatCompletionAgent(\n  kernel=kernel, \n  name=\"<agent name>\", \n  instructions=\"<agent instructions>\",\n  arguments=KernelArguments(settings=settings)\n)\n```\n\n::: zone-end\n\n\n\n## Conversing with `ChatCompletionAgent`\n\n\n\n::: zone pivot=\"programming-language-python\"\n\nThere are multiple ways to converse with a `ChatCompletionAgent`.\n\nThe easiest is to call and await `get_response`:\n\n```python\n# Define agent\nagent = ChatCompletionAgent(...)\n\n# Generate the agent response\nresponse = await agent.get_response(messages=\"user input\")\n# response is an `AgentResponseItem[ChatMessageContent]` object\n```\n\nIf you want the agent to maintain conversation history between invocations, you can pass it a `ChatHistoryAgentThread` as follows:\n\n```python\n\n# Define agent\nagent = ChatCompletionAgent(...)\n\n# Generate the agent response(s)\nresponse = await agent.get_response(messages=\"user input\")\n\n# Generate another response, continuing the conversation thread from the first response.\nresponse2 = await agent.get_response(messages=\"user input\", thread=response.thread)\n# process agent response(s)\n\n```\n\nCalling the `invoke` method returns an `AsyncIterable` of `AgentResponseItem[ChatMessageContent]`.\n\n```python\n# Define agent\nagent = ChatCompletionAgent(...)\n  \n# Define the thread\nthread = ChatHistoryAgentThread()\n\n# Generate the agent response(s)\nasync for response in agent.invoke(messages=\"user input\", thread=thread):\n  # process agent response(s)\n```\n\nThe `ChatCompletionAgent` also supports streaming in which the `invoke_stream` method returns an `AsyncIterable` of `StreamingChatMessageContent`:\n\n```python\n# Define agent\nagent = ChatCompletionAgent(...)\n  \n# Define the thread\nthread = ChatHistoryAgentThread()\n\n# Generate the agent response(s)\nasync for response in agent.invoke_stream(messages=\"user input\", thread=thread):\n  # process agent response(s)\n```\n\n::: zone-end\n\n\n\n## Handling Intermediate Messages with a `ChatCompletionAgent`\n\nThe Semantic Kernel `ChatCompletionAgent` is designed to invoke an agent that fulfills user queries or questions. During invocation, the agent may execute tools to derive the final answer. To access intermediate messages produced during this process, callers can supply a callback function that handles instances of `FunctionCallContent` or `FunctionResultContent`.\n\n\n\n::: zone pivot=\"programming-language-python\"\n\nConfiguring the `on_intermediate_message` callback within `agent.invoke(...)` or `agent.invoke_stream(...)` allows the caller to receive intermediate messages generated during the process of formulating the agent's final response.\n\n```python\nimport asyncio\nfrom typing import Annotated\n\nfrom semantic_kernel.agents import ChatCompletionAgent\nfrom semantic_kernel.connectors.ai.open_ai import AzureChatCompletion\nfrom semantic_kernel.contents import AuthorRole, ChatMessageContent, FunctionCallContent, FunctionResultContent\nfrom semantic_kernel.functions import kernel_function\n\nclass MenuPlugin:\n    \"\"\"A sample Menu Plugin used for the concept sample.\"\"\"\n\n    @kernel_function(description=\"Provides a list of specials from the menu.\")\n    def get_specials(self) -> Annotated[str, \"Returns the specials from the menu.\"]:\n        return \"\"\"\n        Special Soup: Clam Chowder\n        Special Salad: Cobb Salad\n        Special Drink: Chai Tea\n        \"\"\"\n\n    @kernel_function(description=\"Provides the price of the requested menu item.\")\n    def get_item_price(\n        self, menu_item: Annotated[str, \"The name of the menu item.\"]\n    ) -> Annotated[str, \"Returns the price of the menu item.\"]:\n        return \"$9.99\"\n\n# Define a list to hold callback message content\nintermediate_steps: list[ChatMessageContent] = []\n\n# Define an async method to handle the `on_intermediate_message` callback\nasync def handle_intermediate_steps(message: ChatMessageContent) -> None:\n    intermediate_steps.append(message)\n\nasync def main():\n  # Create the ChatCompletionAgent instance\n  agent = ChatCompletionAgent(\n      service=AzureChatCompletion(),\n      instructions=\"your instructions\",\n      name=\"name\",\n      plugins=[MenuPlugin()],\n  )\n\n  user_inputs = [\n      \"Hello\", \n      \"What is the special soup?\", \n      \"What is the special drink?\", \n      \"How much is that?\", \n      \"Thank you\",\n  ]\n\n  thread = None\n\n  # Generate the agent response(s)\n  for user_input in user_inputs:\n      print(f\"# {AuthorRole.USER}: '{user_input}'\")\n      async for response in agent.invoke(\n          messages=user_input,\n          thread=thread,\n          on_intermediate_message=handle_intermediate_steps,\n      ):\n          thread = response.thread\n          print(f\"# {response.name}: {response.content}\")\n\n  # Delete the thread when it is no longer needed\n  await thread.delete() if thread else None\n\n  # Print the intermediate steps\n  print(\"\\nIntermediate Steps:\")\n  for msg in intermediate_steps:\n      if any(isinstance(item, FunctionResultContent) for item in msg.items):\n          for fr in msg.items:\n              if isinstance(fr, FunctionResultContent):\n                  print(f\"Function Result:> {fr.result} for function: {fr.name}\")\n      elif any(isinstance(item, FunctionCallContent) for item in msg.items):\n          for fcc in msg.items:\n              if isinstance(fcc, FunctionCallContent):\n                  print(f\"Function Call:> {fcc.name} with arguments: {fcc.arguments}\")\n      else:\n          print(f\"{msg.role}: {msg.content}\")\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n```\n\nThe following demonstrates sample output from the agent invocation process:\n\n```bash\nSample Output:\n\n# AuthorRole.USER: 'Hello'\n# Host: Hi there! How can I assist you with the menu today?\n# AuthorRole.USER: 'What is the special soup?'\n# Host: The special soup is Clam Chowder.\n# AuthorRole.USER: 'What is the special drink?'\n# Host: The special drink is Chai Tea.\n# AuthorRole.USER: 'How much is that?'\n# Host: Could you please specify the menu item you are asking about?\n# AuthorRole.USER: 'Thank you'\n# Host: You're welcome! If you have any questions about the menu or need assistance, feel free to ask.\n\nIntermediate Steps:\nAuthorRole.ASSISTANT: Hi there! How can I assist you with the menu today?\nAuthorRole.ASSISTANT: \nFunction Result:> \n        Special Soup: Clam Chowder\n        Special Salad: Cobb Salad\n        Special Drink: Chai Tea\n        for function: MenuPlugin-get_specials\nAuthorRole.ASSISTANT: The special soup is Clam Chowder.\nAuthorRole.ASSISTANT: \nFunction Result:> \n        Special Soup: Clam Chowder\n        Special Salad: Cobb Salad\n        Special Drink: Chai Tea\n        for function: MenuPlugin-get_specials\nAuthorRole.ASSISTANT: The special drink is Chai Tea.\nAuthorRole.ASSISTANT: Could you please specify the menu item you are asking about?\nAuthorRole.ASSISTANT: You're welcome! If you have any questions about the menu or need assistance, feel free to ask.\n```\n\n::: zone-end\n\n\n\n### How-To\n\nFor an end-to-end example for a `ChatCompletionAgent`, see:\n\n- [How-To: `ChatCompletionAgent`](./examples/example-chat-agent.md)\n\n> [!div class=\"nextstepaction\"]\n> [Explore the OpenAI Assistant Agent](./assistant-agent.md)",
    "filename": "C:\\Work\\sk\\chainlit-demo\\data\\markdowns\\chat-completion-agent.md",
    "embedding": "Exploring the Semantic Kernel ChatCompletionAgent - An exploration of the definition, behaviors, and usage patterns for a Chat Completion Agent - # Exploring the Semantic Kernel `ChatCompletionAgent`\n\nDetailed API documentation related to this discussion is available at:\n\n\n\n::: zone pivot=\"programming-language-python\"\n\n- [`ChatCompletionAgent`](/python/api/semantic-kernel/semantic_kernel.agents.chat_completion.chat_completion_agent.chatcompletionagent)\n\n::: zone-end\n\n\n\n## Chat Completion in Semantic Kernel\n\n[Chat Completion](../../concepts/ai-services/chat-completion/index.md) is fundamentally a protocol for a chat-based interaction with an AI model where the chat-history is maintained and presented to the model with each request.  Semantic Kernel [AI services](../../concepts/ai-services/index.md) offer a unified framework for integrating the chat-completion capabilities of various AI models.\n\nA `ChatCompletionAgent` can leverage any of these [AI services](../../concepts/ai-services/chat-completion/index.md) to generate responses, whether directed to a user or another agent.\n\n## Preparing Your Development Environment\n\nTo proceed with developing an `ChatCompletionAgent`, configure your development environment with the appropriate packages.\n\n\n\n::: zone pivot=\"programming-language-python\"\n\nInstall the `semantic-kernel` package:\n\n```bash\npip install semantic-kernel\n```\n\n> [!IMPORTANT]\n> Depending upon which AI Service you use as part of the `ChatCompletionAgent`, you may need to install extra packages. Please check for the required extra on the following [page](../../concepts/ai-services/chat-completion/index.md#creating-a-chat-completion-service)\n\n\n::: zone-end\n\n\n\n## Creating a `ChatCompletionAgent`\n\nA `ChatCompletionAgent` is fundamentally based on an [AI services](../../concepts/ai-services/index.md).  As such, creating a `ChatCompletionAgent` starts with creating a [`Kernel`](../../concepts/kernel.md) instance that contains one or more chat-completion services and then instantiating the agent with a reference to that [`Kernel`](../../concepts/kernel.md) instance.\n\n\n\n::: zone pivot=\"programming-language-python\"\nThere are two ways to create a `ChatCompletionAgent`:\n\n### 1. By providing the chat completion service directly\n\n```python\nfrom semantic_kernel.agents import ChatCompletionAgent\n\n# Create the agent by directly providing the chat completion service\nagent = ChatCompletionAgent(\n    service=AzureChatCompletion(),  # your chat completion service instance\n    name=\"<agent name>\",\n    instructions=\"<agent instructions>\",\n)\n```\n\n### 2. By creating a Kernel first, adding the service to it, then providing the kernel\n\n```python\n# Define the kernel\nkernel = Kernel()\n\n# Add the chat completion service to the kernel\nkernel.add_service(AzureChatCompletion())\n\n# Create the agent using the kernel\nagent = ChatCompletionAgent(\n  kernel=kernel, \n  name=\"<agent name>\", \n  instructions=\"<agent instructions>\",\n)\n```\n\nThe first method is useful when you already have a chat completion service ready. The second method is beneficial when you need a kernel that manages multiple services or additional functionalities.\n::: zone-end\n\n\n\n## AI Service Selection\n\nNo different from using Semantic Kernel [AI services](../../concepts/ai-services/index.md) directly, a `ChatCompletionAgent` supports the specification of a service-selector.  A service-selector identifies which [AI service](../../concepts/ai-services/index.md) to target when the [`Kernel`](../../concepts/kernel.md) contains more than one.\n\n> Note: If multiple [AI services](../../concepts/ai-services/index.md) are present and no service-selector is provided, the same default logic is applied for the agent that you'd find when using an [AI services](../../concepts/ai-services/index.md) outside of the `Agent Framework`\n\n\n\n::: zone pivot=\"programming-language-python\"\n\n```python\nfrom semantic_kernel.connectors.ai.open_ai import (\n    AzureChatCompletion,\n    AzureChatPromptExecutionSettings,\n)\n\n# Define the Kernel\nkernel = Kernel()\n\n# Add the AzureChatCompletion AI Service to the Kernel\nkernel.add_service(AzureChatCompletion(service_id=\"service1\"))\nkernel.add_service(AzureChatCompletion(service_id=\"service2\"))\n\nsettings = AzureChatPromptExecutionSettings(service_id=\"service2\")\n\n# Create the agent\nagent = ChatCompletionAgent(\n  kernel=kernel, \n  name=\"<agent name>\", \n  instructions=\"<agent instructions>\",\n  arguments=KernelArguments(settings=settings)\n)\n```\n\n::: zone-end\n\n\n\n## Conversing with `ChatCompletionAgent`\n\n\n\n::: zone pivot=\"programming-language-python\"\n\nThere are multiple ways to converse with a `ChatCompletionAgent`.\n\nThe easiest is to call and await `get_response`:\n\n```python\n# Define agent\nagent = ChatCompletionAgent(...)\n\n# Generate the agent response\nresponse = await agent.get_response(messages=\"user input\")\n# response is an `AgentResponseItem[ChatMessageContent]` object\n```\n\nIf you want the agent to maintain conversation history between invocations, you can pass it a `ChatHistoryAgentThread` as follows:\n\n```python\n\n# Define agent\nagent = ChatCompletionAgent(...)\n\n# Generate the agent response(s)\nresponse = await agent.get_response(messages=\"user input\")\n\n# Generate another response, continuing the conversation thread from the first response.\nresponse2 = await agent.get_response(messages=\"user input\", thread=response.thread)\n# process agent response(s)\n\n```\n\nCalling the `invoke` method returns an `AsyncIterable` of `AgentResponseItem[ChatMessageContent]`.\n\n```python\n# Define agent\nagent = ChatCompletionAgent(...)\n  \n# Define the thread\nthread = ChatHistoryAgentThread()\n\n# Generate the agent response(s)\nasync for response in agent.invoke(messages=\"user input\", thread=thread):\n  # process agent response(s)\n```\n\nThe `ChatCompletionAgent` also supports streaming in which the `invoke_stream` method returns an `AsyncIterable` of `StreamingChatMessageContent`:\n\n```python\n# Define agent\nagent = ChatCompletionAgent(...)\n  \n# Define the thread\nthread = ChatHistoryAgentThread()\n\n# Generate the agent response(s)\nasync for response in agent.invoke_stream(messages=\"user input\", thread=thread):\n  # process agent response(s)\n```\n\n::: zone-end\n\n\n\n## Handling Intermediate Messages with a `ChatCompletionAgent`\n\nThe Semantic Kernel `ChatCompletionAgent` is designed to invoke an agent that fulfills user queries or questions. During invocation, the agent may execute tools to derive the final answer. To access intermediate messages produced during this process, callers can supply a callback function that handles instances of `FunctionCallContent` or `FunctionResultContent`.\n\n\n\n::: zone pivot=\"programming-language-python\"\n\nConfiguring the `on_intermediate_message` callback within `agent.invoke(...)` or `agent.invoke_stream(...)` allows the caller to receive intermediate messages generated during the process of formulating the agent's final response.\n\n```python\nimport asyncio\nfrom typing import Annotated\n\nfrom semantic_kernel.agents import ChatCompletionAgent\nfrom semantic_kernel.connectors.ai.open_ai import AzureChatCompletion\nfrom semantic_kernel.contents import AuthorRole, ChatMessageContent, FunctionCallContent, FunctionResultContent\nfrom semantic_kernel.functions import kernel_function\n\nclass MenuPlugin:\n    \"\"\"A sample Menu Plugin used for the concept sample.\"\"\"\n\n    @kernel_function(description=\"Provides a list of specials from the menu.\")\n    def get_specials(self) -> Annotated[str, \"Returns the specials from the menu.\"]:\n        return \"\"\"\n        Special Soup: Clam Chowder\n        Special Salad: Cobb Salad\n        Special Drink: Chai Tea\n        \"\"\"\n\n    @kernel_function(description=\"Provides the price of the requested menu item.\")\n    def get_item_price(\n        self, menu_item: Annotated[str, \"The name of the menu item.\"]\n    ) -> Annotated[str, \"Returns the price of the menu item.\"]:\n        return \"$9.99\"\n\n# Define a list to hold callback message content\nintermediate_steps: list[ChatMessageContent] = []\n\n# Define an async method to handle the `on_intermediate_message` callback\nasync def handle_intermediate_steps(message: ChatMessageContent) -> None:\n    intermediate_steps.append(message)\n\nasync def main():\n  # Create the ChatCompletionAgent instance\n  agent = ChatCompletionAgent(\n      service=AzureChatCompletion(),\n      instructions=\"your instructions\",\n      name=\"name\",\n      plugins=[MenuPlugin()],\n  )\n\n  user_inputs = [\n      \"Hello\", \n      \"What is the special soup?\", \n      \"What is the special drink?\", \n      \"How much is that?\", \n      \"Thank you\",\n  ]\n\n  thread = None\n\n  # Generate the agent response(s)\n  for user_input in user_inputs:\n      print(f\"# {AuthorRole.USER}: '{user_input}'\")\n      async for response in agent.invoke(\n          messages=user_input,\n          thread=thread,\n          on_intermediate_message=handle_intermediate_steps,\n      ):\n          thread = response.thread\n          print(f\"# {response.name}: {response.content}\")\n\n  # Delete the thread when it is no longer needed\n  await thread.delete() if thread else None\n\n  # Print the intermediate steps\n  print(\"\\nIntermediate Steps:\")\n  for msg in intermediate_steps:\n      if any(isinstance(item, FunctionResultContent) for item in msg.items):\n          for fr in msg.items:\n              if isinstance(fr, FunctionResultContent):\n                  print(f\"Function Result:> {fr.result} for function: {fr.name}\")\n      elif any(isinstance(item, FunctionCallContent) for item in msg.items):\n          for fcc in msg.items:\n              if isinstance(fcc, FunctionCallContent):\n                  print(f\"Function Call:> {fcc.name} with arguments: {fcc.arguments}\")\n      else:\n          print(f\"{msg.role}: {msg.content}\")\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n```\n\nThe following demonstrates sample output from the agent invocation process:\n\n```bash\nSample Output:\n\n# AuthorRole.USER: 'Hello'\n# Host: Hi there! How can I assist you with the menu today?\n# AuthorRole.USER: 'What is the special soup?'\n# Host: The special soup is Clam Chowder.\n# AuthorRole.USER: 'What is the special drink?'\n# Host: The special drink is Chai Tea.\n# AuthorRole.USER: 'How much is that?'\n# Host: Could you please specify the menu item you are asking about?\n# AuthorRole.USER: 'Thank you'\n# Host: You're welcome! If you have any questions about the menu or need assistance, feel free to ask.\n\nIntermediate Steps:\nAuthorRole.ASSISTANT: Hi there! How can I assist you with the menu today?\nAuthorRole.ASSISTANT: \nFunction Result:> \n        Special Soup: Clam Chowder\n        Special Salad: Cobb Salad\n        Special Drink: Chai Tea\n        for function: MenuPlugin-get_specials\nAuthorRole.ASSISTANT: The special soup is Clam Chowder.\nAuthorRole.ASSISTANT: \nFunction Result:> \n        Special Soup: Clam Chowder\n        Special Salad: Cobb Salad\n        Special Drink: Chai Tea\n        for function: MenuPlugin-get_specials\nAuthorRole.ASSISTANT: The special drink is Chai Tea.\nAuthorRole.ASSISTANT: Could you please specify the menu item you are asking about?\nAuthorRole.ASSISTANT: You're welcome! If you have any questions about the menu or need assistance, feel free to ask.\n```\n\n::: zone-end\n\n\n\n### How-To\n\nFor an end-to-end example for a `ChatCompletionAgent`, see:\n\n- [How-To: `ChatCompletionAgent`](./examples/example-chat-agent.md)\n\n> [!div class=\"nextstepaction\"]\n> [Explore the OpenAI Assistant Agent](./assistant-agent.md)"
}
{
    "title": "Process Framework Core Components",
    "description": "Details on the Core Components in the Processes Framework from Semantic Kernel",
    "author": "evchaki",
    "content": "# Core Components of the Process Framework\nThe Process Framework is built upon a modular architecture that enables developers to construct sophisticated workflows through its core components. Understanding these components is essential for effectively leveraging the framework.\n\n## Process\n\nA Process serves as the overarching container that orchestrates the execution of Steps. It defines the flow and routing of data between Steps, ensuring that process goals are achieved efficiently. Processes handle inputs and outputs, providing flexibility and scalability across various workflows.\n\n### Process Features\n\n- **Stateful:** Supports querying information such as tracking status and percent completion, as well as the ability to pause and resume.\n- **Reusable:** A Process can be invoked within other processes, promoting modularity and reusability.\n- **Event Driven:** Employs event-based flow with listeners to route data to Steps and other Processes.\n- **Scalable:** Utilizes well-established runtimes for global scalability and rollouts.\n- **Cloud Event Integrated:** Incorporates industry-standard eventing for triggering a Process or Step.\n\n### Creating A Process\n\nTo create a new Process, add the Process Package to your project and define a name for your process.\n\n\n\n## Step\n\nSteps are the fundamental building blocks within a Process. Each Step corresponds to a discrete unit of work and encapsulates one or more Kernel Functions. Steps can be created independently of their use in specific Processes, enhancing their reusability. They emit events based on the work performed, which can trigger subsequent Steps.\n\n### Step Features\n\n- **Stateful:** Facilitates tracking information such as status and defined tags.\n- **Reusable:** Steps can be employed across multiple Processes.\n- **Dynamic:** Steps can be created dynamically by a Process as needed, depending on the required pattern.\n- **Flexible:** Offers different types of Steps for developers by leveraging Kernel Functions, including Code-only, API calls, AI Agents, and Human-in-the-loop.\n- **Auditable:** Telemetry is enabled across both Steps and Processes.\n\n### Defining a Step\n\nTo create a Step, define a public class to name the Step and add it to the KernelStepBase. Within your class, you can incorporate one or multiple Kernel Functions.\n\n\n\n### Register a Step into a Process\n\nOnce your class is created, you need to register it within your Process. For the first Step in the Process, add `isEntryPoint: true` so the Process knows where to start.\n\n\n\n\n### Step Events\n\nSteps have several events available, including:\n\n- **OnEvent:** Triggered when the class completes its execution.\n- **OnFunctionResult:** Activated when the defined Kernel Function emits results, allowing output to be sent to one or many Steps.\n- **SendOutputTo:** Defines the Step and Input for sending results to a subsequent Step.\n\n\n\n## Pattern\n\nPatterns standardize common process flows, simplifying the implementation of frequently used operations. They promote a consistent approach to solving recurring problems across various implementations, enhancing both maintainability and readability.\n\n### Pattern Types\n\n- **Fan In:** The input for the next Step is supported by multiple outputs from previous Steps.\n- **Fan Out:** The output of previous Steps is directed into multiple Steps further down the Process.\n- **Cycle:** Steps continue to loop until completion based on input and output.\n- **Map Reduce:** Outputs from a Step are consolidated into a smaller amount and directed to the next Step's input.\n\n### Setting up a Pattern\n\nOnce your class is created for your Step and registered within the Process, you can define the events that should be sent downstream to other Steps or set conditions for Steps to be restarted based on the output from your Step.",
    "filename": "C:\\Work\\sk\\chainlit-demo\\data\\markdowns\\process-core-components.md",
    "embedding": "Process Framework Core Components - Details on the Core Components in the Processes Framework from Semantic Kernel - # Core Components of the Process Framework\nThe Process Framework is built upon a modular architecture that enables developers to construct sophisticated workflows through its core components. Understanding these components is essential for effectively leveraging the framework.\n\n## Process\n\nA Process serves as the overarching container that orchestrates the execution of Steps. It defines the flow and routing of data between Steps, ensuring that process goals are achieved efficiently. Processes handle inputs and outputs, providing flexibility and scalability across various workflows.\n\n### Process Features\n\n- **Stateful:** Supports querying information such as tracking status and percent completion, as well as the ability to pause and resume.\n- **Reusable:** A Process can be invoked within other processes, promoting modularity and reusability.\n- **Event Driven:** Employs event-based flow with listeners to route data to Steps and other Processes.\n- **Scalable:** Utilizes well-established runtimes for global scalability and rollouts.\n- **Cloud Event Integrated:** Incorporates industry-standard eventing for triggering a Process or Step.\n\n### Creating A Process\n\nTo create a new Process, add the Process Package to your project and define a name for your process.\n\n\n\n## Step\n\nSteps are the fundamental building blocks within a Process. Each Step corresponds to a discrete unit of work and encapsulates one or more Kernel Functions. Steps can be created independently of their use in specific Processes, enhancing their reusability. They emit events based on the work performed, which can trigger subsequent Steps.\n\n### Step Features\n\n- **Stateful:** Facilitates tracking information such as status and defined tags.\n- **Reusable:** Steps can be employed across multiple Processes.\n- **Dynamic:** Steps can be created dynamically by a Process as needed, depending on the required pattern.\n- **Flexible:** Offers different types of Steps for developers by leveraging Kernel Functions, including Code-only, API calls, AI Agents, and Human-in-the-loop.\n- **Auditable:** Telemetry is enabled across both Steps and Processes.\n\n### Defining a Step\n\nTo create a Step, define a public class to name the Step and add it to the KernelStepBase. Within your class, you can incorporate one or multiple Kernel Functions.\n\n\n\n### Register a Step into a Process\n\nOnce your class is created, you need to register it within your Process. For the first Step in the Process, add `isEntryPoint: true` so the Process knows where to start.\n\n\n\n\n### Step Events\n\nSteps have several events available, including:\n\n- **OnEvent:** Triggered when the class completes its execution.\n- **OnFunctionResult:** Activated when the defined Kernel Function emits results, allowing output to be sent to one or many Steps.\n- **SendOutputTo:** Defines the Step and Input for sending results to a subsequent Step.\n\n\n\n## Pattern\n\nPatterns standardize common process flows, simplifying the implementation of frequently used operations. They promote a consistent approach to solving recurring problems across various implementations, enhancing both maintainability and readability.\n\n### Pattern Types\n\n- **Fan In:** The input for the next Step is supported by multiple outputs from previous Steps.\n- **Fan Out:** The output of previous Steps is directed into multiple Steps further down the Process.\n- **Cycle:** Steps continue to loop until completion based on input and output.\n- **Map Reduce:** Outputs from a Step are consolidated into a smaller amount and directed to the next Step's input.\n\n### Setting up a Pattern\n\nOnce your class is created for your Step and registered within the Process, you can define the events that should be sent downstream to other Steps or set conditions for Steps to be restarted based on the output from your Step."
}
{
    "title": "Process Framework",
    "description": "Details on the Processes Framework from Semantic Kernel",
    "author": "evchaki",
    "content": "# Overview of the Process Framework\n\nWelcome to the Process Framework within Microsoft's Semantic Kernela cutting-edge approach designed to optimize AI integration with your business processes. This framework empowers developers to efficiently create, manage, and deploy business processes while leveraging the powerful capabilities of AI, alongside your existing code and systems.\n\nA Process is a structured sequence of activities or tasks that deliver a service or product, adding value in alignment with specific business goals for customers.\n\n> [!NOTE]\n> Process Framework package is currently experimental and is subject to change until it is moved to preview and GA.\n    \n## Introduction to the Process Framework\n\nThe Process Framework provides a robust solution for automating complex workflows. Each step within the framework performs tasks by invoking user-defined Kernel Functions, utilizing an event-driven model to manage workflow execution.\n\nBy embedding AI into your business processes, you can significantly enhance productivity and decision-making capabilities. With the Process Framework, you benefit from seamless AI integration, facilitating smarter and more responsive workflows. This framework streamlines operations, fosters improved collaboration between business units, and boosts overall efficiency.\n\n\n## Key Features\n\n- **Leverage Semantic Kernel:** Steps can utilize one or multiple Kernel Functions, enabling you to tap into all aspects of Semantic Kernel within your processes.\n- **Reusability & Flexibility:** Steps and processes can be reused across different applications, promoting modularity and scalability.\n- **Event-Driven Architecture:** Utilize events and metadata to trigger actions and transitions between process steps effectively.\n- **Full Control and Auditability:** Maintain control of processes in a defined and repeatable manner, complete with audit capabilities through Open Telemetry.\n\n\n## Core Concepts\n\n- **Process:** A collection of steps arranged to achieve a specific business goal for customers.\n- **Step:** An activity within a process that has defined inputs and outputs, contributing to a larger goal.\n- **Pattern:** The specific sequence type that dictates how steps are executed for the process to be fully completed.\n\n\n## Business Process Examples\n\nBusiness processes are a part of our daily routines. Here are three examples you might have encountered this week:\n\n1. **Account Opening:** This process includes multiple steps such as credit pulls and ratings, fraud detection, creating customer accounts in core systems, and sending welcome information to the customer, including their customer ID.\n2. **Food Delivery:** Ordering food for delivery is a familiar process. From receiving the order via phone, website, or app, to preparing each food item, ensuring quality control, driver assignment, and final delivery, there are many steps in this process that can be streamlined.\n3. **Support Ticket:** We have all submitted support ticketswhether for new services, IT support, or other needs. This process can involve multiple subprocesses based on business and customer requirements, ultimately aiming for satisfaction by addressing customer needs effectively.\n\n\n## Getting Started\n\nAre you ready to harness the power of the Process Framework?\n\nBegin your journey by exploring our [.NET samples](https://aka.ms/sk/process/dotnet) and Python [Python samples](https://github.com/microsoft/semantic-kernel/tree/main/python/samples/getting_started_with_processes) on GitHub.\n\n\nBy diving into the Process Framework, developers can transform traditional workflows into intelligent, adaptive systems. Start building with the tools at your disposal and redefine what's possible with AI-driven business processes.",
    "filename": "C:\\Work\\sk\\chainlit-demo\\data\\markdowns\\process-framework.md",
    "embedding": "Process Framework - Details on the Processes Framework from Semantic Kernel - # Overview of the Process Framework\n\nWelcome to the Process Framework within Microsoft's Semantic Kernela cutting-edge approach designed to optimize AI integration with your business processes. This framework empowers developers to efficiently create, manage, and deploy business processes while leveraging the powerful capabilities of AI, alongside your existing code and systems.\n\nA Process is a structured sequence of activities or tasks that deliver a service or product, adding value in alignment with specific business goals for customers.\n\n> [!NOTE]\n> Process Framework package is currently experimental and is subject to change until it is moved to preview and GA.\n    \n## Introduction to the Process Framework\n\nThe Process Framework provides a robust solution for automating complex workflows. Each step within the framework performs tasks by invoking user-defined Kernel Functions, utilizing an event-driven model to manage workflow execution.\n\nBy embedding AI into your business processes, you can significantly enhance productivity and decision-making capabilities. With the Process Framework, you benefit from seamless AI integration, facilitating smarter and more responsive workflows. This framework streamlines operations, fosters improved collaboration between business units, and boosts overall efficiency.\n\n\n## Key Features\n\n- **Leverage Semantic Kernel:** Steps can utilize one or multiple Kernel Functions, enabling you to tap into all aspects of Semantic Kernel within your processes.\n- **Reusability & Flexibility:** Steps and processes can be reused across different applications, promoting modularity and scalability.\n- **Event-Driven Architecture:** Utilize events and metadata to trigger actions and transitions between process steps effectively.\n- **Full Control and Auditability:** Maintain control of processes in a defined and repeatable manner, complete with audit capabilities through Open Telemetry.\n\n\n## Core Concepts\n\n- **Process:** A collection of steps arranged to achieve a specific business goal for customers.\n- **Step:** An activity within a process that has defined inputs and outputs, contributing to a larger goal.\n- **Pattern:** The specific sequence type that dictates how steps are executed for the process to be fully completed.\n\n\n## Business Process Examples\n\nBusiness processes are a part of our daily routines. Here are three examples you might have encountered this week:\n\n1. **Account Opening:** This process includes multiple steps such as credit pulls and ratings, fraud detection, creating customer accounts in core systems, and sending welcome information to the customer, including their customer ID.\n2. **Food Delivery:** Ordering food for delivery is a familiar process. From receiving the order via phone, website, or app, to preparing each food item, ensuring quality control, driver assignment, and final delivery, there are many steps in this process that can be streamlined.\n3. **Support Ticket:** We have all submitted support ticketswhether for new services, IT support, or other needs. This process can involve multiple subprocesses based on business and customer requirements, ultimately aiming for satisfaction by addressing customer needs effectively.\n\n\n## Getting Started\n\nAre you ready to harness the power of the Process Framework?\n\nBegin your journey by exploring our [.NET samples](https://aka.ms/sk/process/dotnet) and Python [Python samples](https://github.com/microsoft/semantic-kernel/tree/main/python/samples/getting_started_with_processes) on GitHub.\n\n\nBy diving into the Process Framework, developers can transform traditional workflows into intelligent, adaptive systems. Start building with the tools at your disposal and redefine what's possible with AI-driven business processes."
}
{
    "title": "Realtime AI Integrations for Semantic Kernel",
    "description": "Learn about realtime multi-modal AI integrations available in Semantic Kernel.",
    "author": "eavanvalkenburg",
    "content": "# Realtime Multi-modal APIs\n\nThe first realtime API integration for Semantic Kernel has been added, it is currently only available in Python and considered experimental. This is because the underlying services are still being developed and are subject to changes and we might need to make breaking changes to the API in Semantic Kernel as we learn from customers how to use this and as we add other providers of these kinds of models and APIs.\n\n## Realtime Client abstraction\n\nTo support different realtime APIs from different vendors, using different protocols, a new client abstraction has been added to the kernel. This client is used to connect to the realtime service and send and receive messages.\nThe client is responsible for handling the connection to the service, sending messages, and receiving messages. The client is also responsible for handling any errors that occur during the connection or message sending/receiving process. Considering the way these models work, they can be considered agents more than regular chat completions, therefore they also take instructions, rather than a system message, they keep their own internal state and can be invoked to do work on our behalf.\n### Realtime API\n\nAny realtime client implements the following methods:\n\n| Method           | Description                                                                                                        |\n| ---------------- | ------------------------------------------------------------------------------------------------------------------ |\n| `create_session` | Creates a new session                                                                                              |\n| `update_session` | Updates an existing session                                                                                        |\n| `delete_session` | Deletes an existing session                                                                                        |\n| `receive`        | This is a asynchronous generator method that listens for messages from the service and yields them as they arrive. |\n| `send`           | Sends a message to the service                                                                                     |\n\n### Python implementations\n\nThe python version of Semantic Kernel currently supports the following realtime clients:\n\n| Client | Protocol  | Modalities   | Function calling enabled | Description                                                                                                                                                                                        |\n| ------ | --------- | ------------ | ------------------------ | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| OpenAI | Websocket | Text & Audio | Yes                      | The OpenAI Realtime API is a websocket based api that allows you to send and receive messages in realtime, this connector uses the OpenAI Python package to connect and receive and send messages. |\n| OpenAI | WebRTC    | Text & Audio | Yes                      | The OpenAI Realtime API is a WebRTC based api that allows you to send and receive messages in realtime, it needs a webRTC compatible audio track at session creation time.                         |\n| Azure  | Websocket | Text & Audio | Yes                      | The Azure Realtime API is a websocket based api that allows you to send and receive messages in realtime, this uses the same package as the OpenAI websocket connector.                            |\n\n## Getting started\n\nTo get started with the Realtime API, you need to install the `semantic-kernel` package with the `realtime` extra.\n\n```bash\npip install semantic-kernel[realtime]\n```\n\nDepending on how you want to handle audio, you might need additional packages to interface with speakers and microphones, like `pyaudio` or `sounddevice`.\n\n### Websocket clients\n\nThen you can create a kernel and add the realtime client to it, this shows how to do that with a AzureRealtimeWebsocket connection, you can replace AzureRealtimeWebsocket with OpenAIRealtimeWebsocket without any further changes.\n\n```python\nfrom semantic_kernel.connectors.ai.open_ai import (\n    AzureRealtimeWebsocket,\n    AzureRealtimeExecutionSettings,\n    ListenEvents,\n)\nfrom semantic_kernel.contents import RealtimeAudioEvent, RealtimeTextEvent\n\n# this will use environment variables to get the api key, endpoint, api version and deployment name.\nrealtime_client = AzureRealtimeWebsocket()\nsettings = AzureRealtimeExecutionSettings(voice='alloy')\nasync with realtime_client(settings=settings, create_response=True):\n    async for event in realtime_client.receive():\n        match event:\n            # receiving a piece of audio (and send it to a undefined audio player)\n            case RealtimeAudioEvent():\n                await audio_player.add_audio(event.audio)\n            # receiving a piece of audio transcript\n            case RealtimeTextEvent():\n                # Semantic Kernel parses the transcript to a TextContent object captured in a RealtimeTextEvent\n                print(event.text.text, end=\"\")\n            case _:\n                # OpenAI Specific events\n                if event.service_type == ListenEvents.SESSION_UPDATED:\n                    print(\"Session updated\")\n                if event.service_type == ListenEvents.RESPONSE_CREATED:\n                    print(\"\\nMosscap (transcript): \", end=\"\")\n```\n\nThere are two important things to note, the first is that the `realtime_client` is an async context manager, this means that you can use it in an async function and use `async with` to create the session.\nThe second is that the `receive` method is an async generator, this means that you can use it in a for loop to receive messages as they arrive.\n\n### WebRTC client\n\nThe setup of a WebRTC connection is a bit more complex and so we need a extra parameter when creating the client. This parameter, `audio_track` needs to be a object that implements the `MediaStreamTrack` protocol of the `aiortc` package, this is also demonstrated in the samples that are linked below.\n\nTo create a client that uses WebRTC, you would do the following:\n\n```python\nfrom semantic_kernel.connectors.ai.open_ai import (\n    ListenEvents,\n    OpenAIRealtimeExecutionSettings,\n    OpenAIRealtimeWebRTC,\n)\nfrom aiortc.mediastreams import MediaStreamTrack\n\nclass AudioRecorderWebRTC(MediaStreamTrack):\n    # implement the MediaStreamTrack methods.\n\nrealtime_client = OpenAIRealtimeWebRTC(audio_track=AudioRecorderWebRTC())\n# Create the settings for the session\nsettings = OpenAIRealtimeExecutionSettings(\n    instructions=\"\"\"\nYou are a chat bot. Your name is Mosscap and\nyou have one goal: figure out what people need.\nYour full name, should you need to know it, is\nSplendid Speckled Mosscap. You communicate\neffectively, but you tend to answer with long\nflowery prose.\n\"\"\",\n    voice=\"shimmer\",\n)\naudio_player = AudioPlayer\nasync with realtime_client(settings=settings, create_response=True):\n    async for event in realtime_client.receive():\n        match event.event_type:\n            # receiving a piece of audio (and send it to a undefined audio player)\n            case \"audio\":\n                await audio_player.add_audio(event.audio)\n            case \"text\":\n                # the model returns both audio and transcript of the audio, which we will print\n                print(event.text.text, end=\"\")\n            case \"service\":\n                # OpenAI Specific events\n                if event.service_type == ListenEvents.SESSION_UPDATED:\n                    print(\"Session updated\")\n                if event.service_type == ListenEvents.RESPONSE_CREATED:\n                    print(\"\\nMosscap (transcript): \", end=\"\")\n```\n\nBoth of these samples receive the audio as RealtimeAudioEvent and then they pass that to a unspecified audio_player object.\n\n### Audio output callback\n\nNext to this we have a parameter called `audio_output_callback`  on the `receive` method and on the class creation. This callback will be called first before any further handling of the audio and gets a `numpy` array of the audio data, instead of it being parsed into AudioContent and returned as a RealtimeAudioEvent that you can then handle, which is what happens above. This has shown to give smoother audio output because there is less overhead between the audio data coming in and it being given to the player.\n\nThis example shows how to define and use the `audio_output_callback`:\n\n```python\nfrom semantic_kernel.connectors.ai.open_ai import (\n    ListenEvents,\n    OpenAIRealtimeExecutionSettings,\n    OpenAIRealtimeWebRTC,\n)\nfrom aiortc.mediastreams import MediaStreamTrack\n\nclass AudioRecorderWebRTC(MediaStreamTrack):\n    # implement the MediaStreamTrack methods.\n\nclass AudioPlayer:\n    async def play_audio(self, content: np.ndarray):\n        # implement the audio player\n\nrealtime_client = OpenAIRealtimeWebRTC(audio_track=AudioRecorderWebRTC())\n# Create the settings for the session\nsettings = OpenAIRealtimeExecutionSettings(\n    instructions=\"\"\"\nYou are a chat bot. Your name is Mosscap and\nyou have one goal: figure out what people need.\nYour full name, should you need to know it, is\nSplendid Speckled Mosscap. You communicate\neffectively, but you tend to answer with long\nflowery prose.\n\"\"\",\n    voice=\"shimmer\",\n)\naudio_player = AudioPlayer\nasync with realtime_client(settings=settings, create_response=True):\n    async for event in realtime_client.receive(audio_output_callback=audio_player.play_audio):\n        match event.event_type:\n            # no need to handle case: \"audio\"\n            case \"text\":\n                # the model returns both audio and transcript of the audio, which we will print\n                print(event.text.text, end=\"\")\n            case \"service\":\n                # OpenAI Specific events\n                if event.service_type == ListenEvents.SESSION_UPDATED:\n                    print(\"Session updated\")\n                if event.service_type == ListenEvents.RESPONSE_CREATED:\n                    print(\"\\nMosscap (transcript): \", end=\"\")\n```\n\n### Samples\n\nThere are four samples in [our repo](https://github.com/microsoft/semantic-kernel/tree/main/python/samples/concepts/realtime), they cover both the basics using both websockets and WebRTC, as well as a more complex setup including function calling. Finally there is a more [complex demo](https://github.com/microsoft/semantic-kernel/tree/main/python/samples/demos/call_automation) that uses [Azure Communication Services](/azure/communication-services/) to allow you to call your Semantic Kernel enhanced realtime API.",
    "filename": "C:\\Work\\sk\\chainlit-demo\\data\\markdowns\\realtime.md",
    "embedding": "Realtime AI Integrations for Semantic Kernel - Learn about realtime multi-modal AI integrations available in Semantic Kernel. - # Realtime Multi-modal APIs\n\nThe first realtime API integration for Semantic Kernel has been added, it is currently only available in Python and considered experimental. This is because the underlying services are still being developed and are subject to changes and we might need to make breaking changes to the API in Semantic Kernel as we learn from customers how to use this and as we add other providers of these kinds of models and APIs.\n\n## Realtime Client abstraction\n\nTo support different realtime APIs from different vendors, using different protocols, a new client abstraction has been added to the kernel. This client is used to connect to the realtime service and send and receive messages.\nThe client is responsible for handling the connection to the service, sending messages, and receiving messages. The client is also responsible for handling any errors that occur during the connection or message sending/receiving process. Considering the way these models work, they can be considered agents more than regular chat completions, therefore they also take instructions, rather than a system message, they keep their own internal state and can be invoked to do work on our behalf.\n### Realtime API\n\nAny realtime client implements the following methods:\n\n| Method           | Description                                                                                                        |\n| ---------------- | ------------------------------------------------------------------------------------------------------------------ |\n| `create_session` | Creates a new session                                                                                              |\n| `update_session` | Updates an existing session                                                                                        |\n| `delete_session` | Deletes an existing session                                                                                        |\n| `receive`        | This is a asynchronous generator method that listens for messages from the service and yields them as they arrive. |\n| `send`           | Sends a message to the service                                                                                     |\n\n### Python implementations\n\nThe python version of Semantic Kernel currently supports the following realtime clients:\n\n| Client | Protocol  | Modalities   | Function calling enabled | Description                                                                                                                                                                                        |\n| ------ | --------- | ------------ | ------------------------ | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| OpenAI | Websocket | Text & Audio | Yes                      | The OpenAI Realtime API is a websocket based api that allows you to send and receive messages in realtime, this connector uses the OpenAI Python package to connect and receive and send messages. |\n| OpenAI | WebRTC    | Text & Audio | Yes                      | The OpenAI Realtime API is a WebRTC based api that allows you to send and receive messages in realtime, it needs a webRTC compatible audio track at session creation time.                         |\n| Azure  | Websocket | Text & Audio | Yes                      | The Azure Realtime API is a websocket based api that allows you to send and receive messages in realtime, this uses the same package as the OpenAI websocket connector.                            |\n\n## Getting started\n\nTo get started with the Realtime API, you need to install the `semantic-kernel` package with the `realtime` extra.\n\n```bash\npip install semantic-kernel[realtime]\n```\n\nDepending on how you want to handle audio, you might need additional packages to interface with speakers and microphones, like `pyaudio` or `sounddevice`.\n\n### Websocket clients\n\nThen you can create a kernel and add the realtime client to it, this shows how to do that with a AzureRealtimeWebsocket connection, you can replace AzureRealtimeWebsocket with OpenAIRealtimeWebsocket without any further changes.\n\n```python\nfrom semantic_kernel.connectors.ai.open_ai import (\n    AzureRealtimeWebsocket,\n    AzureRealtimeExecutionSettings,\n    ListenEvents,\n)\nfrom semantic_kernel.contents import RealtimeAudioEvent, RealtimeTextEvent\n\n# this will use environment variables to get the api key, endpoint, api version and deployment name.\nrealtime_client = AzureRealtimeWebsocket()\nsettings = AzureRealtimeExecutionSettings(voice='alloy')\nasync with realtime_client(settings=settings, create_response=True):\n    async for event in realtime_client.receive():\n        match event:\n            # receiving a piece of audio (and send it to a undefined audio player)\n            case RealtimeAudioEvent():\n                await audio_player.add_audio(event.audio)\n            # receiving a piece of audio transcript\n            case RealtimeTextEvent():\n                # Semantic Kernel parses the transcript to a TextContent object captured in a RealtimeTextEvent\n                print(event.text.text, end=\"\")\n            case _:\n                # OpenAI Specific events\n                if event.service_type == ListenEvents.SESSION_UPDATED:\n                    print(\"Session updated\")\n                if event.service_type == ListenEvents.RESPONSE_CREATED:\n                    print(\"\\nMosscap (transcript): \", end=\"\")\n```\n\nThere are two important things to note, the first is that the `realtime_client` is an async context manager, this means that you can use it in an async function and use `async with` to create the session.\nThe second is that the `receive` method is an async generator, this means that you can use it in a for loop to receive messages as they arrive.\n\n### WebRTC client\n\nThe setup of a WebRTC connection is a bit more complex and so we need a extra parameter when creating the client. This parameter, `audio_track` needs to be a object that implements the `MediaStreamTrack` protocol of the `aiortc` package, this is also demonstrated in the samples that are linked below.\n\nTo create a client that uses WebRTC, you would do the following:\n\n```python\nfrom semantic_kernel.connectors.ai.open_ai import (\n    ListenEvents,\n    OpenAIRealtimeExecutionSettings,\n    OpenAIRealtimeWebRTC,\n)\nfrom aiortc.mediastreams import MediaStreamTrack\n\nclass AudioRecorderWebRTC(MediaStreamTrack):\n    # implement the MediaStreamTrack methods.\n\nrealtime_client = OpenAIRealtimeWebRTC(audio_track=AudioRecorderWebRTC())\n# Create the settings for the session\nsettings = OpenAIRealtimeExecutionSettings(\n    instructions=\"\"\"\nYou are a chat bot. Your name is Mosscap and\nyou have one goal: figure out what people need.\nYour full name, should you need to know it, is\nSplendid Speckled Mosscap. You communicate\neffectively, but you tend to answer with long\nflowery prose.\n\"\"\",\n    voice=\"shimmer\",\n)\naudio_player = AudioPlayer\nasync with realtime_client(settings=settings, create_response=True):\n    async for event in realtime_client.receive():\n        match event.event_type:\n            # receiving a piece of audio (and send it to a undefined audio player)\n            case \"audio\":\n                await audio_player.add_audio(event.audio)\n            case \"text\":\n                # the model returns both audio and transcript of the audio, which we will print\n                print(event.text.text, end=\"\")\n            case \"service\":\n                # OpenAI Specific events\n                if event.service_type == ListenEvents.SESSION_UPDATED:\n                    print(\"Session updated\")\n                if event.service_type == ListenEvents.RESPONSE_CREATED:\n                    print(\"\\nMosscap (transcript): \", end=\"\")\n```\n\nBoth of these samples receive the audio as RealtimeAudioEvent and then they pass that to a unspecified audio_player object.\n\n### Audio output callback\n\nNext to this we have a parameter called `audio_output_callback`  on the `receive` method and on the class creation. This callback will be called first before any further handling of the audio and gets a `numpy` array of the audio data, instead of it being parsed into AudioContent and returned as a RealtimeAudioEvent that you can then handle, which is what happens above. This has shown to give smoother audio output because there is less overhead between the audio data coming in and it being given to the player.\n\nThis example shows how to define and use the `audio_output_callback`:\n\n```python\nfrom semantic_kernel.connectors.ai.open_ai import (\n    ListenEvents,\n    OpenAIRealtimeExecutionSettings,\n    OpenAIRealtimeWebRTC,\n)\nfrom aiortc.mediastreams import MediaStreamTrack\n\nclass AudioRecorderWebRTC(MediaStreamTrack):\n    # implement the MediaStreamTrack methods.\n\nclass AudioPlayer:\n    async def play_audio(self, content: np.ndarray):\n        # implement the audio player\n\nrealtime_client = OpenAIRealtimeWebRTC(audio_track=AudioRecorderWebRTC())\n# Create the settings for the session\nsettings = OpenAIRealtimeExecutionSettings(\n    instructions=\"\"\"\nYou are a chat bot. Your name is Mosscap and\nyou have one goal: figure out what people need.\nYour full name, should you need to know it, is\nSplendid Speckled Mosscap. You communicate\neffectively, but you tend to answer with long\nflowery prose.\n\"\"\",\n    voice=\"shimmer\",\n)\naudio_player = AudioPlayer\nasync with realtime_client(settings=settings, create_response=True):\n    async for event in realtime_client.receive(audio_output_callback=audio_player.play_audio):\n        match event.event_type:\n            # no need to handle case: \"audio\"\n            case \"text\":\n                # the model returns both audio and transcript of the audio, which we will print\n                print(event.text.text, end=\"\")\n            case \"service\":\n                # OpenAI Specific events\n                if event.service_type == ListenEvents.SESSION_UPDATED:\n                    print(\"Session updated\")\n                if event.service_type == ListenEvents.RESPONSE_CREATED:\n                    print(\"\\nMosscap (transcript): \", end=\"\")\n```\n\n### Samples\n\nThere are four samples in [our repo](https://github.com/microsoft/semantic-kernel/tree/main/python/samples/concepts/realtime), they cover both the basics using both websockets and WebRTC, as well as a more complex setup including function calling. Finally there is a more [complex demo](https://github.com/microsoft/semantic-kernel/tree/main/python/samples/demos/call_automation) that uses [Azure Communication Services](/azure/communication-services/) to allow you to call your Semantic Kernel enhanced realtime API."
}
